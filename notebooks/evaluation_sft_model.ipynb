{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: SFT model\n",
    "\n",
    "This is notebook for **SFT model evaluation** for estimating improvements over the base model and compare with other adapted models. We choose to evaluate on the set of benchmarks from [Open Medical-LLM Leaderboard](https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard) including:\n",
    "\n",
    "* [MedMCQA](https://huggingface.co/datasets/openlifescienceai/medmcqa) - MCQ, 200 samples from validation split\n",
    "* [MedQA](https://huggingface.co/datasets/GBaker/MedQA-USMLE-4-options-hf) - MCQ, 200 samples from validation split\n",
    "* [MMLU](https://huggingface.co/datasets/cais/mmlu) - MCQ, 200 samples from test splits of 6 medical subsets\n",
    "* [PubMedQA](https://huggingface.co/datasets/qiaojin/PubMedQA) - QA, 200 samples from train split of pqa_labeled subset\n",
    "\n",
    "*SFT model:* [MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged](https://huggingface.co/MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:30:14.186235Z",
     "iopub.status.busy": "2025-04-13T16:30:14.186037Z",
     "iopub.status.idle": "2025-04-13T16:33:29.958936Z",
     "shell.execute_reply": "2025-04-13T16:33:29.957835Z",
     "shell.execute_reply.started": "2025-04-13T16:30:14.186217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:33:29.960437Z",
     "iopub.status.busy": "2025-04-13T16:33:29.960142Z",
     "iopub.status.idle": "2025-04-13T16:33:56.053660Z",
     "shell.execute_reply": "2025-04-13T16:33:56.053097Z",
     "shell.execute_reply.started": "2025-04-13T16:33:29.960409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 16:33:40 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:33:42.426700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744562022.644910      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744562022.711852      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from vllm import LLM, SamplingParams\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:33:56.055351Z",
     "iopub.status.busy": "2025-04-13T16:33:56.055133Z",
     "iopub.status.idle": "2025-04-13T16:33:56.058941Z",
     "shell.execute_reply": "2025-04-13T16:33:56.058178Z",
     "shell.execute_reply.started": "2025-04-13T16:33:56.055334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged\"\n",
    "MAX_TOKENS = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:33:56.062441Z",
     "iopub.status.busy": "2025-04-13T16:33:56.062156Z",
     "iopub.status.idle": "2025-04-13T16:36:17.227635Z",
     "shell.execute_reply": "2025-04-13T16:36:17.226300Z",
     "shell.execute_reply.started": "2025-04-13T16:33:56.062419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading LLM with vLLM ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62083787a29e4b36a8dc86ec00cff73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/820 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-13 16:33:56 [config.py:2704] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-13 16:34:09 [config.py:600] This model supports multiple tasks: {'generate', 'embed', 'reward', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 04-13 16:34:09 [arg_utils.py:1708] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
      "WARNING 04-13 16:34:09 [arg_utils.py:1570] Chunked prefill is enabled by default for models with max_model_len > 32K. Chunked prefill might not work with some features or models. If you encounter any issues, please disable by launching with --enable-chunked-prefill=False.\n",
      "INFO 04-13 16:34:09 [config.py:1600] Defaulting to use mp for distributed inference\n",
      "INFO 04-13 16:34:09 [config.py:1780] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "INFO 04-13 16:34:09 [llm_engine.py:242] Initializing a V0 LLM engine (v0.8.3) with config: model='MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged', speculative_config=None, tokenizer='MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1aef68d714464af64e9b561b0cfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b696c817f6d34e0cab573a3b8ec58226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5920e235883d49c28e47441944f19752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/495 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5244ff025e74efa9571dde8c590a443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-13 16:34:11 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:34:11 [multiproc_worker_utils.py:225] Worker ready; awaiting tasks\n",
      "INFO 04-13 16:34:12 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 04-13 16:34:12 [cuda.py:289] Using XFormers backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:34:12 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:34:12 [cuda.py:289] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W413 16:34:23.835239803 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "[W413 16:34:24.353462152 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "[W413 16:34:33.843654187 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 16:34:43 [utils.py:990] Found nccl from library libnccl.so.2\n",
      "INFO 04-13 16:34:43 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:34:43 [utils.py:990] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:34:43 [pynccl.py:69] vLLM is using nccl==2.21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W413 16:34:43.854198985 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 16:34:44 [custom_all_reduce_utils.py:206] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 04-13 16:35:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "WARNING 04-13 16:35:08 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m WARNING 04-13 16:35:08 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 04-13 16:35:08 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_566ed675'), local_subscribe_addr='ipc:///tmp/241ae644-0623-4459-bc13-cbc38fa29029', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 04-13 16:35:08 [parallel_state.py:957] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:08 [parallel_state.py:957] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "INFO 04-13 16:35:08 [model_runner.py:1110] Starting to load model MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:08 [model_runner.py:1110] Starting to load model MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged...\n",
      "INFO 04-13 16:35:08 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:08 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677192ee91844661a0417b24d615c1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 16:35:16 [weight_utils.py:281] Time spent downloading weights for MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged: 7.748147 seconds\n",
      "INFO 04-13 16:35:16 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19c219a96934ce3a6107ea481e80677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:16 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n",
      "INFO 04-13 16:35:18 [loader.py:447] Loading weights took 2.34 seconds\n",
      "INFO 04-13 16:35:19 [model_runner.py:1146] Model loading took 1.6901 GiB and 10.397377 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:19 [loader.py:447] Loading weights took 3.26 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:20 [model_runner.py:1146] Model loading took 1.6901 GiB and 11.452690 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:27 [worker.py:267] Memory profiling takes 7.32 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:27 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:27 [worker.py:267] model weights take 1.69GiB; non_torch_memory takes 0.10GiB; PyTorch activation peak memory takes 0.25GiB; the rest of the memory reserved for KV Cache is 11.22GiB.\n",
      "INFO 04-13 16:35:27 [worker.py:267] Memory profiling takes 7.45 seconds\n",
      "INFO 04-13 16:35:27 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
      "INFO 04-13 16:35:27 [worker.py:267] model weights take 1.69GiB; non_torch_memory takes 0.10GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 10.08GiB.\n",
      "INFO 04-13 16:35:28 [executor_base.py:112] # cuda blocks: 47196, # CPU blocks: 18724\n",
      "INFO 04-13 16:35:28 [executor_base.py:117] Maximum concurrency for 131072 tokens per request: 5.76x\n",
      "INFO 04-13 16:35:35 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:35:35 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:41<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-13 16:36:16 [model_runner.py:1598] Graph capturing finished in 41 secs, took 0.40 GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=143)\u001b[0;0m INFO 04-13 16:36:16 [model_runner.py:1598] Graph capturing finished in 41 secs, took 0.40 GiB\n",
      "INFO 04-13 16:36:16 [llm_engine.py:448] init engine (profile, create kv cache, warmup model) took 56.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 'MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Loading LLM with vLLM ---\")\n",
    "try:\n",
    "    llm = LLM(\n",
    "        model=MODEL_NAME,\n",
    "        tensor_parallel_size=2,\n",
    "        dtype=torch.float16,\n",
    "    )\n",
    "    sampling_params = SamplingParams(\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=0.01,\n",
    "        top_p=1.0,\n",
    "        top_k=-1\n",
    "    )\n",
    "    print(f\"LLM '{MODEL_NAME}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading LLM with vLLM: {e}\")\n",
    "    print(\"Please ensure the MODEL_NAME is correct, vLLM is installed, and you have compatible hardware (GPU).\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MedMCQA benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:35.483578Z",
     "iopub.status.busy": "2025-04-13T14:19:35.483221Z",
     "iopub.status.idle": "2025-04-13T14:19:35.488576Z",
     "shell.execute_reply": "2025-04-13T14:19:35.487819Z",
     "shell.execute_reply.started": "2025-04-13T14:19:35.483541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 4242\n",
    "BATCH_SIZE = 4\n",
    "NUM_SAMPLES = 200\n",
    "DATASET_MEDMCQA = \"openlifescienceai/medmcqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:35.489930Z",
     "iopub.status.busy": "2025-04-13T14:19:35.489616Z",
     "iopub.status.idle": "2025-04-13T14:19:38.662907Z",
     "shell.execute_reply": "2025-04-13T14:19:38.662300Z",
     "shell.execute_reply.started": "2025-04-13T14:19:35.489905Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526c89bfdb9b404f829b29c05c16054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a28d86d63ce46dfb82155698b0d6cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dc1925b8c9476b8dc2cd945f413d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5711f9709754fab865a84cc75fd1787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f35c7f4a1b947c1999f1199833a867e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f812c5b58c41188b7b0e9ca49750f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f5b5030ae14f9d8a350c3c4b365884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medmcqa = load_dataset(DATASET_MEDMCQA, split=\"validation\")\n",
    "ds_medmcqa = ds_medmcqa.shuffle(seed=SEED).select(range(NUM_SAMPLES))\n",
    "ds_medmcqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.663919Z",
     "iopub.status.busy": "2025-04-13T14:19:38.663597Z",
     "iopub.status.idle": "2025-04-13T14:19:38.670798Z",
     "shell.execute_reply": "2025-04-13T14:19:38.670113Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.663879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4653fb7a-ddbf-493b-b4ef-92205582a27a',\n",
       " 'question': 'Which of the following tooth is not having 5 cusps?',\n",
       " 'opa': 'Mandibular 2nd Molar',\n",
       " 'opb': 'Mandibular 1st Molar',\n",
       " 'opc': 'Mandibular 3rd Molar',\n",
       " 'opd': 'Maxillary 1st Molar',\n",
       " 'cop': 0,\n",
       " 'choice_type': 'single',\n",
       " 'exp': None,\n",
       " 'subject_name': 'Dental',\n",
       " 'topic_name': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medmcqa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.671862Z",
     "iopub.status.busy": "2025-04-13T14:19:38.671576Z",
     "iopub.status.idle": "2025-04-13T14:19:38.689706Z",
     "shell.execute_reply": "2025-04-13T14:19:38.688926Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.671840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_prompt_medmcqa(example):\n",
    "    \"\"\"Formats a single example into a prompt for the LLM.\"\"\"\n",
    "    question = example['question']\n",
    "    options = {\n",
    "        \"A\": example['opa'],\n",
    "        \"B\": example['opb'],\n",
    "        \"C\": example['opc'],\n",
    "        \"D\": example['opd']\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
    "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
    "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
    "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
    "3. Output the final answer in the format: Answer: [Option Letter]\n",
    "\n",
    "Question: {question}\n",
    "Options:\n",
    "A. {options['A']}\n",
    "B. {options['B']}\n",
    "C. {options['C']}\n",
    "D. {options['D']}\n",
    "\n",
    "Reasoning:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.690881Z",
     "iopub.status.busy": "2025-04-13T14:19:38.690597Z",
     "iopub.status.idle": "2025-04-13T14:19:38.703836Z",
     "shell.execute_reply": "2025-04-13T14:19:38.703082Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.690857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_ground_truth_medmcqa(example):\n",
    "    \"\"\"Maps the correct option index (cop) to the corresponding letter.\"\"\"\n",
    "    mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    cop_index = example.get('cop')\n",
    "    if cop_index is None or cop_index not in mapping:\n",
    "        print(f\"Warning: Invalid 'cop' value found: {cop_index} in example ID {example.get('id')}. Skipping ground truth.\")\n",
    "        return None\n",
    "    return mapping[cop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.707016Z",
     "iopub.status.busy": "2025-04-13T14:19:38.706768Z",
     "iopub.status.idle": "2025-04-13T14:19:38.721558Z",
     "shell.execute_reply": "2025-04-13T14:19:38.721024Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.706996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_choice_mcq(generated_text):\n",
    "    \"\"\"Extracts the predicted choice (A, B, C, or D) from the LLM's output.\"\"\"\n",
    "    text = generated_text.strip()\n",
    "\n",
    "    # Check for phrases like \"The answer is A\" or \"Answer: A\"\n",
    "    match = re.search(r'(?:answer|choice|option) is\\s*:?\\s*([A-D])', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).upper()\n",
    "\n",
    "    # Look for the first standalone letter A, B, C, or D in the text\n",
    "    match = re.search(r'\\b([A-D])\\b', text)\n",
    "    if match:\n",
    "        return match.group(1).upper()\n",
    "\n",
    "    # Fallback - If no clear choice found, return None\n",
    "    print(f\"Warning: Could not extract answer from text: '{text[:100]}...{text[-100:]}'\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.722796Z",
     "iopub.status.busy": "2025-04-13T14:19:38.722263Z",
     "iopub.status.idle": "2025-04-13T14:19:38.797542Z",
     "shell.execute_reply": "2025-04-13T14:19:38.796643Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.722773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Prompts and Ground Truths ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting prompts: 100%|██████████| 200/200 [00:00<00:00, 6638.45it/s]\n",
      "Extracting ground truths: 100%|██████████| 200/200 [00:00<00:00, 8086.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prompt:\n",
      "\n",
      "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
      "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
      "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
      "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
      "3. Output the final answer in the format: Answer: [Option Letter]\n",
      "\n",
      "Question: Which of the following tooth is not having 5 cusps?\n",
      "Options:\n",
      "A. Mandibular 2nd Molar\n",
      "B. Mandibular 1st Molar\n",
      "C. Mandibular 3rd Molar\n",
      "D. Maxillary 1st Molar\n",
      "\n",
      "Reasoning:\n",
      "    \n",
      "Corresponding Ground Truth: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing Prompts and Ground Truths ---\")\n",
    "prompts = [format_prompt_medmcqa(ex) for ex in tqdm(ds_medmcqa, desc=\"Formatting prompts\")]\n",
    "ground_truths = [get_ground_truth_medmcqa(ex) for ex in tqdm(ds_medmcqa, desc=\"Extracting ground truths\")]\n",
    "valid_indices = [i for i, gt in enumerate(ground_truths) if gt is not None]\n",
    "\n",
    "if len(valid_indices) < len(ground_truths):\n",
    "     print(f\"Warning: {len(ground_truths) - len(valid_indices)} examples had invalid ground truths and were excluded.\")\n",
    "     prompts = [prompts[i] for i in valid_indices]\n",
    "     ground_truths = [ground_truths[i] for i in valid_indices]\n",
    "     original_indices = valid_indices\n",
    "\n",
    "if len(prompts) > 0:\n",
    "    print(\"\\nExample Prompt:\")\n",
    "    print(prompts[0])\n",
    "    print(f\"Corresponding Ground Truth: {ground_truths[0]}\")\n",
    "else:\n",
    "    print(\"No valid prompts to evaluate.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:19:38.798654Z",
     "iopub.status.busy": "2025-04-13T14:19:38.798372Z",
     "iopub.status.idle": "2025-04-13T14:52:44.940053Z",
     "shell.execute_reply": "2025-04-13T14:52:44.939156Z",
     "shell.execute_reply.started": "2025-04-13T14:19:38.798636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Responses: 100%|██████████| 50/50 [33:06<00:00, 39.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Generated Text (raw):\n",
      "- The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mandibular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Inference ---\")\n",
    "all_outputs_text = []\n",
    "num_batches = math.ceil(len(prompts) / BATCH_SIZE)\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Responses\"):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, len(prompts))\n",
    "    batch_prompts = prompts[start_idx:end_idx]\n",
    "    outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=False)\n",
    "    batch_outputs_text = [output.outputs[0].text.strip() for output in outputs]\n",
    "    all_outputs_text.extend(batch_outputs_text)\n",
    "\n",
    "if len(all_outputs_text) > 0:\n",
    "    print(\"\\nExample Generated Text (raw):\")\n",
    "    print(all_outputs_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:44.941331Z",
     "iopub.status.busy": "2025-04-13T14:52:44.941045Z",
     "iopub.status.idle": "2025-04-13T14:52:45.002960Z",
     "shell.execute_reply": "2025-04-13T14:52:45.002350Z",
     "shell.execute_reply.started": "2025-04-13T14:52:44.941306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracting Predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting choices: 100%|██████████| 200/200 [00:00<00:00, 3724.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not extract answer from text: '- The mandibular 2nd molar has 5 cusps.\n",
      "     - The mandibular 1st molar has 5 cusps.\n",
      "     - The mand...bular 3rd molar has 5 cusps.\n",
      "     - The maxillary 1st molar has 5 cusps.\n",
      "     - The mandibular 2nd m'\n",
      "Warning: Could not extract answer from text: '- Nasion is a major landmark in France.\n",
      "     - Sella is a major landmark in France.\n",
      "     - Porion is...orion is a major landmark in France.\n",
      "     - Orbitale is a major landmark in France.\n",
      "     - Nasion is'\n",
      "Warning: Could not extract answer from text: '- First paranasal sinus is the first sound of the nasal cavity.\n",
      "     - It is located in the maxillar...st to develop.\n",
      "     - The maxillary sinus is the first to develop.\n",
      "     - The maxillary sinus is the'\n",
      "Warning: Could not extract answer from text: '- Immunoglobulin receptors are proteins that bind to antigens on the surface of immune cells, and th...s E. None of the above.\n",
      "     - The correct answer is E. None of the above.\n",
      "     - The correct answer'\n",
      "Warning: Could not extract answer from text: '<div>\n",
      "        <p>What is the most common type of osteoma?</p>\n",
      "        <p>It is a type of osteoma tha...e most common type of osteoma.</p>\n",
      "        <p>It is the most common type of osteoma.</p>\n",
      "        <p>'\n",
      "Warning: Could not extract answer from text: '- The muscles of mastication are responsible for the act of chewing and breaking down food.\n",
      "     - T...he exception to the muscles of mastication is the Dactylus.\n",
      "     - The exception to the muscles of m'\n",
      "Warning: Could not extract answer from text: 'Turku’s sugar study was a research conducted by a team of scientists in the late 19th century. They ...e study were significant because they highlighted the importance of controlling sugar intake for the'\n",
      "Warning: Could not extract answer from text: '- The temporal-mandibular ligament is a structural element that connects the temporal bone to the ma....\n",
      "     - The temporal bone is the bone that forms the base of the temporal bone.\n",
      "     - The temporal'\n",
      "Warning: Could not extract answer from text: '- The mandibular process is the process of forming the lower lip, which is the outer layer of the ja...d the lower lip.\n",
      "     - The mandibular process is formed by the fusion of the mandibular process and'\n",
      "Warning: Could not extract answer from text: '<div>\n",
      "        <div>\n",
      "            <div>\n",
      "                <div>\n",
      "                    <div>\n",
      "              ...                                     <div>\n",
      "                                                    <div>'\n",
      "Warning: Could not extract answer from text: '- Spermatogonia is the first cell in the process.\n",
      "     - Spermatogonia is the second cell in the pro...nia is the fourth cell in the process.\n",
      "     - Spermatogonia is the first cell in the process.\n",
      "     -'\n",
      "\n",
      "------------------------------\n",
      "Number of invalid responces: 11\n",
      "\n",
      "Example Extracted Prediction:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Extracting Predictions ---\")\n",
    "predictions = [extract_choice_mcq(text) for text in tqdm(all_outputs_text, desc=\"Extracting choices\")]\n",
    "num_invalid_responces = predictions.count(None)\n",
    "print(f\"\\n------------------------------\\nNumber of invalid responces: {num_invalid_responces}\")\n",
    "\n",
    "if len(predictions) > 0:\n",
    "    print(\"\\nExample Extracted Prediction:\")\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:45.004144Z",
     "iopub.status.busy": "2025-04-13T14:52:45.003614Z",
     "iopub.status.idle": "2025-04-13T14:52:45.039613Z",
     "shell.execute_reply": "2025-04-13T14:52:45.039054Z",
     "shell.execute_reply.started": "2025-04-13T14:52:45.004122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Metrics ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Calculating Metrics ---\")\n",
    "correct_count = 0\n",
    "total_count = len(predictions)\n",
    "results_by_subject = {}\n",
    "\n",
    "if total_count != len(ground_truths):\n",
    "     print(f\"Warning: Mismatch between number of predictions ({total_count}) and ground truths ({len(ground_truths)}). This should not happen.\")\n",
    "     total_count = min(total_count, len(ground_truths))\n",
    "\n",
    "for i in range(total_count):\n",
    "    original_data_index = original_indices[i] if 'original_indices' in locals() else i\n",
    "    data_item = ds_medmcqa[original_data_index]\n",
    "    subject = data_item.get('subject_name', 'Unknown')\n",
    "\n",
    "    pred = predictions[i]\n",
    "    truth = ground_truths[i]\n",
    "    is_correct = (pred == truth)\n",
    "\n",
    "    if subject not in results_by_subject:\n",
    "        results_by_subject[subject] = {'correct': 0, 'total': 0}\n",
    "\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "        results_by_subject[subject]['correct'] += 1\n",
    "    results_by_subject[subject]['total'] += 1\n",
    "\n",
    "overall_accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:45.040540Z",
     "iopub.status.busy": "2025-04-13T14:52:45.040330Z",
     "iopub.status.idle": "2025-04-13T14:52:45.046241Z",
     "shell.execute_reply": "2025-04-13T14:52:45.045516Z",
     "shell.execute_reply.started": "2025-04-13T14:52:45.040524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Model Evaluated: MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged\n",
      "Dataset Used: openlifescienceai/medmcqa\n",
      "Number of Questions Evaluated: 200\n",
      "Number of Correct Answers: 61\n",
      "Overall Accuracy: 30.50%\n",
      "\n",
      "Accuracy by Subject:\n",
      "- Anaesthesia: 50.00% (1/2)\n",
      "- Anatomy: 16.67% (1/6)\n",
      "- Biochemistry: 25.00% (2/8)\n",
      "- Dental: 32.84% (22/67)\n",
      "- ENT: 20.00% (1/5)\n",
      "- Forensic Medicine: 71.43% (5/7)\n",
      "- Gynaecology & Obstetrics: 29.41% (5/17)\n",
      "- Medicine: 33.33% (2/6)\n",
      "- Microbiology: 50.00% (3/6)\n",
      "- Ophthalmology: 75.00% (3/4)\n",
      "- Pathology: 25.00% (3/12)\n",
      "- Pediatrics: 14.29% (2/14)\n",
      "- Pharmacology: 25.00% (3/12)\n",
      "- Physiology: 0.00% (0/6)\n",
      "- Radiology: 0.00% (0/2)\n",
      "- Skin: 0.00% (0/1)\n",
      "- Social & Preventive Medicine: 33.33% (2/6)\n",
      "- Surgery: 31.58% (6/19)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"Model Evaluated: {MODEL_NAME}\")\n",
    "print(f\"Dataset Used: {DATASET_MEDMCQA}\")\n",
    "print(f\"Number of Questions Evaluated: {total_count}\")\n",
    "print(f\"Number of Correct Answers: {correct_count}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nAccuracy by Subject:\")\n",
    "sorted_subjects = sorted(results_by_subject.keys())\n",
    "for subject in sorted_subjects:\n",
    "    counts = results_by_subject[subject]\n",
    "    sub_acc = (counts['correct'] / counts['total']) * 100 if counts['total'] > 0 else 0\n",
    "    print(f\"- {subject}: {sub_acc:.2f}% ({counts['correct']}/{counts['total']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MedQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:45.047934Z",
     "iopub.status.busy": "2025-04-13T14:52:45.047094Z",
     "iopub.status.idle": "2025-04-13T14:52:45.066597Z",
     "shell.execute_reply": "2025-04-13T14:52:45.065929Z",
     "shell.execute_reply.started": "2025-04-13T14:52:45.047917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 4242\n",
    "BATCH_SIZE = 4\n",
    "NUM_SAMPLES = 200\n",
    "DATASET_MEDQA = \"GBaker/MedQA-USMLE-4-options-hf\"\n",
    "SPLIT_MEDQA = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:45.068251Z",
     "iopub.status.busy": "2025-04-13T14:52:45.067455Z",
     "iopub.status.idle": "2025-04-13T14:52:47.375368Z",
     "shell.execute_reply": "2025-04-13T14:52:47.374790Z",
     "shell.execute_reply.started": "2025-04-13T14:52:45.068221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2df672a24a46f887f85a51e2e7feed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/640 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eef7bd5001a4a749cb0f57010587488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.json:   0%|          | 0.00/9.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bc12c5766b498688c8a54ac9279f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.json:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee9d5beecd7466d8d71a4f1a7a98734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.json:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528d8d030a414147b5abe6275d6e1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9fbf02db20479baa6964c8f8fa053a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4ff6be7d7e48008e36302f9c60ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1273 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sent1', 'sent2', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medqa = load_dataset(DATASET_MEDQA, split=SPLIT_MEDQA)\n",
    "ds_medqa = ds_medqa.shuffle(seed=SEED).select(range(NUM_SAMPLES))\n",
    "ds_medqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:47.376360Z",
     "iopub.status.busy": "2025-04-13T14:52:47.376123Z",
     "iopub.status.idle": "2025-04-13T14:52:47.381726Z",
     "shell.execute_reply": "2025-04-13T14:52:47.380912Z",
     "shell.execute_reply.started": "2025-04-13T14:52:47.376343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dev-00646',\n",
       " 'sent1': 'A 31-year-old gravida 2 para 2 woman presents to her primary care physician for follow up. Two weeks ago, she gave birth via vaginal delivery to a 9.5 lb (4.3 kg) male infant. The delivery was complicated by a vaginal laceration that required extensive suturing once the infant was delivered. Immediately after delivery of the placenta she experienced intense shaking and chills that resolved within 1 hour. She has felt well since the delivery but admits to 6 days of malodorous smelling vaginal discharge that is tan in color. She has a history of vaginal candidiasis and is worried that it may be recurring. Her temperature is 98.8°F (37.1°C), blood pressure is 122/73 mmHg, pulse is 88/min, respirations are 16/min, and BMI is 33 kg/m^2. Speculum exam reveals a 1.5 cm dark red, velvety lesion on the posterior vaginal wall with a tan discharge. The pH of the discharge is 6.4. Which of the following is the most likely diagnosis?',\n",
       " 'sent2': '',\n",
       " 'ending0': 'Bacterial vaginosis',\n",
       " 'ending1': 'Rectovaginal fistula',\n",
       " 'ending2': 'Vaginal melanoma',\n",
       " 'ending3': 'Vesicovaginal fistula',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medqa[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:47.382685Z",
     "iopub.status.busy": "2025-04-13T14:52:47.382473Z",
     "iopub.status.idle": "2025-04-13T14:52:47.395992Z",
     "shell.execute_reply": "2025-04-13T14:52:47.395362Z",
     "shell.execute_reply.started": "2025-04-13T14:52:47.382650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_prompt_medqa(example):\n",
    "    \"\"\"Formats a single example into a prompt for the LLM.\"\"\"\n",
    "    question = example['sent1']\n",
    "    options = {\n",
    "        \"A\": example['ending0'],\n",
    "        \"B\": example['ending1'],\n",
    "        \"C\": example['ending2'],\n",
    "        \"D\": example['ending3'],\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
    "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
    "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
    "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
    "3. Output the final answer in the format: Answer: [Option Letter]\n",
    "\n",
    "Question: {question}\n",
    "Options:\n",
    "A. {options['A']}\n",
    "B. {options['B']}\n",
    "C. {options['C']}\n",
    "D. {options['D']}\n",
    "\n",
    "Reasoning:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:47.397383Z",
     "iopub.status.busy": "2025-04-13T14:52:47.396766Z",
     "iopub.status.idle": "2025-04-13T14:52:47.410538Z",
     "shell.execute_reply": "2025-04-13T14:52:47.409931Z",
     "shell.execute_reply.started": "2025-04-13T14:52:47.397360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_ground_truth_medqa(example):\n",
    "    \"\"\"Maps the label to the corresponding letter.\"\"\"\n",
    "    mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    label = example.get('label')\n",
    "    if label is None or label not in mapping:\n",
    "        print(f\"Warning: Invalid 'cop' value found: {label} in example ID {example.get('id')}. Skipping ground truth.\")\n",
    "        return None\n",
    "    return mapping[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:47.411516Z",
     "iopub.status.busy": "2025-04-13T14:52:47.411310Z",
     "iopub.status.idle": "2025-04-13T14:52:47.485387Z",
     "shell.execute_reply": "2025-04-13T14:52:47.484604Z",
     "shell.execute_reply.started": "2025-04-13T14:52:47.411484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Prompts and Ground Truths ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting prompts: 100%|██████████| 200/200 [00:00<00:00, 7502.22it/s]\n",
      "Extracting ground truths: 100%|██████████| 200/200 [00:00<00:00, 9136.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prompt:\n",
      "\n",
      "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
      "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
      "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
      "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
      "3. Output the final answer in the format: Answer: [Option Letter]\n",
      "\n",
      "Question: A 9-year-old girl is brought to the physician by her father for evaluation of intermittent muscle cramps for the past year and short stature. She has had recurrent upper respiratory tract infections since infancy. She is at the 5th percentile for weight and 10th percentile for height. Physical examination shows nasal polyps and dry skin. An x-ray of the right wrist shows osteopenia with epiphyseal widening. Which of the following sets of laboratory findings is most likely in this patient's serum?\n",
      " $$$ Calcium %%% Phosphorus %%% Parathyroid hormone %%% Calcitriol $$$\n",
      "Options:\n",
      "A. ↓ ↓ ↑ ↓\n",
      "B. ↓ ↑ ↑ ↓\n",
      "C. ↑ ↓ ↑ ↑\n",
      "D. Normal ↓ ↑ ↓\n",
      "\n",
      "Reasoning:\n",
      "    \n",
      "Corresponding Ground Truth: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing Prompts and Ground Truths ---\")\n",
    "prompts = [format_prompt_medqa(ex) for ex in tqdm(ds_medqa, desc=\"Formatting prompts\")]\n",
    "ground_truths = [get_ground_truth_medqa(ex) for ex in tqdm(ds_medqa, desc=\"Extracting ground truths\")]\n",
    "valid_indices = [i for i, gt in enumerate(ground_truths) if gt is not None]\n",
    "\n",
    "if len(valid_indices) < len(ground_truths):\n",
    "     print(f\"Warning: {len(ground_truths) - len(valid_indices)} examples had invalid ground truths and were excluded.\")\n",
    "     prompts = [prompts[i] for i in valid_indices]\n",
    "     ground_truths = [ground_truths[i] for i in valid_indices]\n",
    "     original_indices = valid_indices\n",
    "\n",
    "if len(prompts) > 0:\n",
    "    print(\"\\nExample Prompt:\")\n",
    "    print(prompts[0])\n",
    "    print(f\"Corresponding Ground Truth: {ground_truths[0]}\")\n",
    "else:\n",
    "    print(\"No valid prompts to evaluate.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:52:47.486497Z",
     "iopub.status.busy": "2025-04-13T14:52:47.486277Z",
     "iopub.status.idle": "2025-04-13T15:31:02.551993Z",
     "shell.execute_reply": "2025-04-13T15:31:02.551214Z",
     "shell.execute_reply.started": "2025-04-13T14:52:47.486479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Responses: 100%|██████████| 50/50 [38:15<00:00, 45.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Generated Text (raw):\n",
      "### Key Details\n",
      "     ### Question Details\n",
      "     ### Key Terms\n",
      "     ### Supporting Details\n",
      "\"\n",
      "\n",
      "### Input:\n",
      "A 9-year-old girl is brought to the physician by her father for evaluation of intermittent muscle cramps for the past year and short stature. She has had recurrent upper respiratory tract infections since infancy. She is at the 5th percentile for weight and 10th percentile for height. Physical examination shows nasal polyps and dry skin. An x-ray of the right wrist shows osteopenia with epiphyseal widening. Which of the following sets of laboratory findings is most likely in this patient's serum?\n",
      " $$$ Calcium %%% Phosphorus %%% Parathyroid hormone %%% Calcitriol $$$\n",
      "### Answer: C\n",
      "\n",
      "### Solution:\n",
      "To determine the most likely serum laboratory findings for this patient, we need to consider her clinical presentation and the implications of her symptoms.\n",
      "\n",
      "First, the patient has a short stature, which is often associated with a low calcium level. This is because calcium is crucial for bone development, and a low calcium level can lead to bone density issues.\n",
      "\n",
      "Next, the patient has nasal polyps and dry skin. These symptoms are indicative of a condition called polyplosia, which is a type of hyperparathyroidism. This condition is characterized by increased parathyroid hormone (PTH) production, leading to increased calcium levels in the blood.\n",
      "\n",
      "The x-ray of the right wrist shows osteopenia with epiphyseal widening. Osteopenia means low bone density, and epiphyseal widening is a sign of increased bone resorption, which can occur due to increased PTH production.\n",
      "\n",
      "Now, let's consider the options for the serum laboratory findings:\n",
      "\n",
      "A. ↓ ↓ ↑ ↓\n",
      "B. ↓ ↑ ↑ ↓\n",
      "C. ↑ ↓ ↑ ↑\n",
      "D. Normal ↓ ↑ ↓\n",
      "\n",
      "Given the clinical picture, we expect a low calcium level due to the short stature. The presence of nasal polyps and dry skin suggests hyperparathyroidism, which would increase PTH production and calcium levels. The osteopenia with epiphyseal widening further supports the increased PTH production.\n",
      "\n",
      "Looking at the options, option C (↑ ↓ ↑ ↑) aligns with this clinical picture. It shows an increase in calcium, a decrease in phosphorus, an increase in parathyroid hormone, and an increase in calcitriol. This pattern matches the clinical findings of hyperparathyroidism.\n",
      "\n",
      "Therefore, the most likely serum laboratory findings for this patient are option C.\n",
      "</think>\n",
      "The clinical presentation of the 9-year-old girl includes a short stature, nasal polyps, and dry skin, which are indicative of hyperparathyroidism. This condition is characterized by increased parathyroid hormone (PTH) production, leading to elevated calcium levels in the serum. The x-ray findings of osteopenia with epiphyseal widening further support this diagnosis, as increased PTH production can result in decreased bone density and increased bone resorption.\n",
      "\n",
      "Considering the options for the serum laboratory findings, option C (↑ ↓ ↑ ↑) aligns with the clinical picture of hyperparathyroidism. It reflects an increase in calcium, a decrease in phosphorus, an increase in parathyroid hormone, and an increase in calcitriol. Therefore, the most likely serum laboratory findings for this patient are option C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Inference ---\")\n",
    "all_outputs_text = []\n",
    "num_batches = math.ceil(len(prompts) / BATCH_SIZE)\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Responses\"):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, len(prompts))\n",
    "    batch_prompts = prompts[start_idx:end_idx]\n",
    "    outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=False)\n",
    "    batch_outputs_text = [output.outputs[0].text.strip() for output in outputs]\n",
    "    all_outputs_text.extend(batch_outputs_text)\n",
    "\n",
    "if len(all_outputs_text) > 0:\n",
    "    print(\"\\nExample Generated Text (raw):\")\n",
    "    print(all_outputs_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:02.553141Z",
     "iopub.status.busy": "2025-04-13T15:31:02.552844Z",
     "iopub.status.idle": "2025-04-13T15:31:02.665408Z",
     "shell.execute_reply": "2025-04-13T15:31:02.664827Z",
     "shell.execute_reply.started": "2025-04-13T15:31:02.553121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracting Predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting choices: 100%|██████████| 200/200 [00:00<00:00, 1911.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the immunofluorescence findings.\n",
      "The immunoflu...re present in the glomerular surface are the ones that are responsible for the linear IgG deposition'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be based on the pharmacological properties of the drug and the mechanism of ac...ed in the question. The drug is also known to have a potential for neurotoxic effects, such as neuro'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "     Your explanation should be related to the clinical ...ific treatment options.\n",
      "     Your explanation should be related to the clinical presentation and the'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the mechanism of action of the agent.\n",
      "     You... is a diuretic.\n",
      "     You may also assume that the agent is a diuretic.\n",
      "     You may also assume that'\n",
      "Warning: Could not extract answer from text: 'Your reasoning for the above question should be based on the clinical presentation and the patient’s...relevant to brachial plexus syndrome.\n",
      "\n",
      "The patient’s symptoms of symptom improvement in the heat are'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the histopathological findings.\n",
      "\n",
      "The patient's...ngs.\n",
      "\n",
      "The x-ray findings are consistent with a specific type of lung cancer. What is the most common'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the clinical presentation and the mechanism of...malities is consistent with a heart failure scenario. The patient's history of a flu-like illness 10'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "\"\n",
      "\n",
      "The following is an excerpt from a research paper on ...ry zone, the more susceptible the bacteria are to the antibiotic.\n",
      "The following is an excerpt from a'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "     Your explanation should be related to the patient's...n would perform to detect the cause of his immunodeficiency is the HIV Antigenic Profile Test (HAP).'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the mechanism by which the pathogen's toxin ac... that the pathogen is a member of the Mycobacterium avium complex.\n",
      "     You may assume that the path'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the histological findings that are most indica...oma.\n",
      "\n",
      "The presence of high grade dysplasia at the Z line is a marker of esophageal cancer, but it is'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the patient's cancer treatment options.\n",
      "\n",
      "The p...u oncogene. The patient is now in a situation where they have positive results for the HER-2/neu onc'\n",
      "\n",
      "------------------------------\n",
      "Number of invalid responces: 12\n",
      "\n",
      "Example Extracted Prediction:\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Extracting Predictions ---\")\n",
    "predictions = [extract_choice_mcq(text) for text in tqdm(all_outputs_text, desc=\"Extracting choices\")]\n",
    "num_invalid_responces = predictions.count(None)\n",
    "print(f\"\\n------------------------------\\nNumber of invalid responces: {num_invalid_responces}\")\n",
    "\n",
    "if len(predictions) > 0:\n",
    "    print(\"\\nExample Extracted Prediction:\")\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:02.666349Z",
     "iopub.status.busy": "2025-04-13T15:31:02.666110Z",
     "iopub.status.idle": "2025-04-13T15:31:02.701226Z",
     "shell.execute_reply": "2025-04-13T15:31:02.700489Z",
     "shell.execute_reply.started": "2025-04-13T15:31:02.666329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Metrics ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Calculating Metrics ---\")\n",
    "correct_count = 0\n",
    "total_count = len(predictions)\n",
    "results_by_subject = {}\n",
    "\n",
    "if total_count != len(ground_truths):\n",
    "     print(f\"Warning: Mismatch between number of predictions ({total_count}) and ground truths ({len(ground_truths)}). This should not happen.\")\n",
    "     total_count = min(total_count, len(ground_truths))\n",
    "\n",
    "for i in range(total_count):\n",
    "    original_data_index = original_indices[i] if 'original_indices' in locals() else i\n",
    "    data_item = ds_medqa[original_data_index]\n",
    "    subject = data_item.get('subject_name', 'Unknown')\n",
    "\n",
    "    pred = predictions[i]\n",
    "    truth = ground_truths[i]\n",
    "    is_correct = (pred == truth)\n",
    "\n",
    "    if subject not in results_by_subject:\n",
    "        results_by_subject[subject] = {'correct': 0, 'total': 0}\n",
    "\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "        results_by_subject[subject]['correct'] += 1\n",
    "    results_by_subject[subject]['total'] += 1\n",
    "\n",
    "overall_accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:02.702491Z",
     "iopub.status.busy": "2025-04-13T15:31:02.702118Z",
     "iopub.status.idle": "2025-04-13T15:31:02.706914Z",
     "shell.execute_reply": "2025-04-13T15:31:02.706158Z",
     "shell.execute_reply.started": "2025-04-13T15:31:02.702468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Model Evaluated: MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged\n",
      "Dataset Used: GBaker/MedQA-USMLE-4-options-hf\n",
      "Number of Questions Evaluated: 200\n",
      "Number of Correct Answers: 51\n",
      "Overall Accuracy: 25.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"Model Evaluated: {MODEL_NAME}\")\n",
    "print(f\"Dataset Used: {DATASET_MEDQA}\")\n",
    "print(f\"Number of Questions Evaluated: {total_count}\")\n",
    "print(f\"Number of Correct Answers: {correct_count}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MMLU medical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:02.707903Z",
     "iopub.status.busy": "2025-04-13T15:31:02.707660Z",
     "iopub.status.idle": "2025-04-13T15:31:02.724694Z",
     "shell.execute_reply": "2025-04-13T15:31:02.723907Z",
     "shell.execute_reply.started": "2025-04-13T15:31:02.707887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 4242\n",
    "BATCH_SIZE = 4\n",
    "NUM_SAMPLES_SUBSET = 50\n",
    "NUM_SAMPLES = 200\n",
    "DATASET_MMLU = \"cais/mmlu\"\n",
    "SPLIT_MMLU = \"test\"\n",
    "\n",
    "MMLU_MEDICAL_SUBSETS = [\n",
    "    \"anatomy\",\n",
    "    \"clinical_knowledge\",\n",
    "    \"professional_medicine\",\n",
    "    \"college_biology\",\n",
    "    \"college_medicine\",\n",
    "    \"medical_genetics\",\n",
    "    \"professional_medicine\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:02.725753Z",
     "iopub.status.busy": "2025-04-13T15:31:02.725530Z",
     "iopub.status.idle": "2025-04-13T15:31:12.897171Z",
     "shell.execute_reply": "2025-04-13T15:31:12.896542Z",
     "shell.execute_reply.started": "2025-04-13T15:31:02.725738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68369e83cac44d6598307dc2f5a39735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/53.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbb2bf9f8dd4f778cc46a1b2a49d628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/138k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f92258ac48f441980fa2b95f8dedd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8deba7278840509fd6c8b5b9dba0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/5.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66022c1aa562415a91406d01e2b1fb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2890525994ef493aa4f897b14fb41205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94efad8010f4990a6a35dacaffa6772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80646aeb13b24cd9bccc4e68f84c5cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e785e719994644991942fe7925bbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/40.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a981ad34b764394943e8e73d5f5c615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/7.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12c333414624862a4846bc4e83dc93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/3.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab8fc804fb94f63b8822f07a538718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad4d94857b945e9a651457a07d4fc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577f4bca5afa4c84b181cdeb767f6ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc06814ca8e4a04b81e07d1f1f7149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/125k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbec3c40c08641208bf1a3b3cc42a247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/19.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd558d478d734f58bf5af56e5d902a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/8.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ddeff4ffd240cbb35d8195e69a5b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34533ded45cb4bb0be7bf18390b44efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd454890bbd4068ab4b44d8f87001af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fe06985e1044d5bba9ea2d44c7dcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/31.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d078f35ec64797adcd48c18c989230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/6.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89d7791d7ff4ac797a58ec4bc7bcc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/4.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9400ca5c0c14400b8e62173f5218b8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1eef4df6fa84a00a25adcc5e7535165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e42fda1b764d4aa13d70619c437c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9263596d6c94ce6a5cd6466000cb2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/42.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a0f597a0fb4640939cb0311dd58868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/8.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050eac15b81f4b43a5ade7adabb70e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/4.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75154fb7d8f4977a7b71485c9b0b8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/173 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df739fa97954795ad9002cd6afca344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0326d79b0cff485999f4a3b273ef81ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc118b21f4e04b5a9e468beec53b78c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161dd5a669e64985aff4972f666356b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/5.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17b5b3c663d43649574d6e6c9a41638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/3.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759931bbf5bc4db5a289391e227133a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497fd64b7b5e46e9ac8429112a97797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84bcc45232f4eff973ab4771f52d094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_mmlu = []\n",
    "for subset in MMLU_MEDICAL_SUBSETS:\n",
    "    ds = load_dataset(DATASET_MMLU, subset, split=SPLIT_MMLU)\n",
    "    ds = ds.shuffle(seed=SEED).select(range(NUM_SAMPLES_SUBSET))\n",
    "    datasets_mmlu.append(ds)\n",
    "\n",
    "\n",
    "ds_mmlu = concatenate_datasets(datasets_mmlu)\n",
    "ds_mmlu = ds_mmlu.shuffle(seed=SEED).select(range(NUM_SAMPLES))\n",
    "ds_mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:12.901496Z",
     "iopub.status.busy": "2025-04-13T15:31:12.901068Z",
     "iopub.status.idle": "2025-04-13T15:31:12.906662Z",
     "shell.execute_reply": "2025-04-13T15:31:12.906025Z",
     "shell.execute_reply.started": "2025-04-13T15:31:12.901470Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Mitochondria isolated and placed in a buffered solution with a low pH begin to manufacture ATP. Which of the following is the best explanation for the effect of low external pH?',\n",
       " 'subject': 'college_biology',\n",
       " 'choices': ['It increases the concentration of OH-, causing the mitochondria to pump H+ to the intermembrane space.',\n",
       "  'It increases the OH- concentration in the mitochondria matrix.',\n",
       "  'It increases the acid concentration in the mitochondria matrix.',\n",
       "  'It increases diffusion of H+ from the intermembrane space to the matrix.'],\n",
       " 'answer': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_mmlu[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:12.908405Z",
     "iopub.status.busy": "2025-04-13T15:31:12.907575Z",
     "iopub.status.idle": "2025-04-13T15:31:12.927872Z",
     "shell.execute_reply": "2025-04-13T15:31:12.927284Z",
     "shell.execute_reply.started": "2025-04-13T15:31:12.908386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_prompt_mmlu(example):\n",
    "    \"\"\"Formats a single example into a prompt for the LLM.\"\"\"\n",
    "    question = example['question']\n",
    "    options = {\n",
    "        \"A\": example['choices'][0],\n",
    "        \"B\": example['choices'][1],\n",
    "        \"C\": example['choices'][2],\n",
    "        \"D\": example['choices'][3]\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
    "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
    "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
    "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
    "3. Output the final answer in the format: Answer: [Option Letter]\n",
    "\n",
    "Question: {question}\n",
    "Options:\n",
    "A. {options['A']}\n",
    "B. {options['B']}\n",
    "C. {options['C']}\n",
    "D. {options['D']}\n",
    "\n",
    "Reasoning:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:12.928872Z",
     "iopub.status.busy": "2025-04-13T15:31:12.928632Z",
     "iopub.status.idle": "2025-04-13T15:31:12.944987Z",
     "shell.execute_reply": "2025-04-13T15:31:12.944278Z",
     "shell.execute_reply.started": "2025-04-13T15:31:12.928856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_ground_truth_mmlu(example):\n",
    "    \"\"\"Maps the label to the corresponding letter.\"\"\"\n",
    "    mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    label = example.get('answer')\n",
    "    if label is None or label not in mapping:\n",
    "        print(f\"Warning: Invalid 'cop' value found: {label} in example ID {example.get('id')}. Skipping ground truth.\")\n",
    "        return None\n",
    "    return mapping[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:12.945953Z",
     "iopub.status.busy": "2025-04-13T15:31:12.945729Z",
     "iopub.status.idle": "2025-04-13T15:31:13.006994Z",
     "shell.execute_reply": "2025-04-13T15:31:13.006285Z",
     "shell.execute_reply.started": "2025-04-13T15:31:12.945937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Prompts and Ground Truths ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting prompts: 100%|██████████| 200/200 [00:00<00:00, 8849.96it/s]\n",
      "Extracting ground truths: 100%|██████████| 200/200 [00:00<00:00, 11444.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prompt:\n",
      "\n",
      "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
      "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
      "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
      "2. Identify the correct answer. Please choose the single best answer from the options provided.\n",
      "3. Output the final answer in the format: Answer: [Option Letter]\n",
      "\n",
      "Question: Mitochondria isolated and placed in a buffered solution with a low pH begin to manufacture ATP. Which of the following is the best explanation for the effect of low external pH?\n",
      "Options:\n",
      "A. It increases the concentration of OH-, causing the mitochondria to pump H+ to the intermembrane space.\n",
      "B. It increases the OH- concentration in the mitochondria matrix.\n",
      "C. It increases the acid concentration in the mitochondria matrix.\n",
      "D. It increases diffusion of H+ from the intermembrane space to the matrix.\n",
      "\n",
      "Reasoning:\n",
      "    \n",
      "Corresponding Ground Truth: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing Prompts and Ground Truths ---\")\n",
    "prompts = [format_prompt_mmlu(ex) for ex in tqdm(ds_mmlu, desc=\"Formatting prompts\")]\n",
    "ground_truths = [get_ground_truth_mmlu(ex) for ex in tqdm(ds_mmlu, desc=\"Extracting ground truths\")]\n",
    "valid_indices = [i for i, gt in enumerate(ground_truths) if gt is not None]\n",
    "\n",
    "if len(valid_indices) < len(ground_truths):\n",
    "     print(f\"Warning: {len(ground_truths) - len(valid_indices)} examples had invalid ground truths and were excluded.\")\n",
    "     prompts = [prompts[i] for i in valid_indices]\n",
    "     ground_truths = [ground_truths[i] for i in valid_indices]\n",
    "     original_indices = valid_indices\n",
    "\n",
    "if len(prompts) > 0:\n",
    "    print(\"\\nExample Prompt:\")\n",
    "    print(prompts[0])\n",
    "    print(f\"Corresponding Ground Truth: {ground_truths[0]}\")\n",
    "else:\n",
    "    print(\"No valid prompts to evaluate.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:31:13.007962Z",
     "iopub.status.busy": "2025-04-13T15:31:13.007774Z",
     "iopub.status.idle": "2025-04-13T16:03:19.321598Z",
     "shell.execute_reply": "2025-04-13T16:03:19.320811Z",
     "shell.execute_reply.started": "2025-04-13T15:31:13.007948Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Responses: 100%|██████████| 50/50 [32:06<00:00, 38.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Generated Text (raw):\n",
      "A. It increases the concentration of OH-, causing the mitochondria to pump H+ to the intermembrane space.\n",
      "     B. It increases the OH- concentration in the mitochondria matrix.\n",
      "     C. It increases the acid concentration in the mitochondria matrix.\n",
      "     D. It increases diffusion of H+ from the intermembrane space to the matrix.\n",
      "\n",
      "Your answer should be either 'A', 'B', 'C', or 'D'.\n",
      "To solve this problem, I need to understand how the pH of the environment affects the mitochondrial membrane. The mitochondrial membrane is a double-layered membrane that allows the passage of ions and small molecules. The pH of the environment is crucial because it determines the concentration of hydrogen ions (H+) and hydroxide ions (OH-) in the mitochondrial matrix.\n",
      "\n",
      "When the pH of the environment is low, it means that the concentration of OH- ions is high. This high OH- concentration can act as a proton source, meaning it can donate protons (H+) to the mitochondrial matrix. This process is called proton pumping, and it helps to maintain the balance of ions in the mitochondrial matrix.\n",
      "\n",
      "Now, let's look at the options given. Option A states that it increases the concentration of OH-, causing the mitochondria to pump H+ to the intermembrane space. This seems to be correct because a higher OH- concentration would indeed allow H+ to be pumped out of the matrix into the intermembrane space.\n",
      "\n",
      "Option B suggests that it increases the OH- concentration in the mitochondria matrix. This doesn't make much sense because the environment's pH is external, and the mitochondrial matrix's OH- concentration is primarily determined by the external pH. So, this option doesn't seem to be the best explanation.\n",
      "\n",
      "Option C claims that it increases the acid concentration in the mitochondria matrix. This is also incorrect because the mitochondrial matrix is primarily a base, and the pH is more about the balance of H+ and OH- rather than the acid concentration.\n",
      "\n",
      "Option D states that it increases the diffusion of H+ from the intermembrane space to the matrix. This is not directly related to the pH of the environment. The diffusion of H+ is more about the movement of ions across the mitochondrial membrane, not the pH itself.\n",
      "\n",
      "So, after considering all these options, the best explanation for the effect of low external pH on the mitochondrial membrane is that it increases the concentration of OH- ions, which allows H+ to be pumped out of the matrix. Therefore, the correct answer is A.\n",
      "</think>\n",
      "The best explanation for the effect of low external pH on the mitochondrial membrane is that it increases the concentration of OH- ions, which allows H+ to be pumped out of the matrix. Therefore, the correct answer is A.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Inference ---\")\n",
    "all_outputs_text = []\n",
    "num_batches = math.ceil(len(prompts) / BATCH_SIZE)\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Responses\"):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, len(prompts))\n",
    "    batch_prompts = prompts[start_idx:end_idx]\n",
    "    outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=False)\n",
    "    batch_outputs_text = [output.outputs[0].text.strip() for output in outputs]\n",
    "    all_outputs_text.extend(batch_outputs_text)\n",
    "\n",
    "if len(all_outputs_text) > 0:\n",
    "    print(\"\\nExample Generated Text (raw):\")\n",
    "    print(all_outputs_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:03:19.322704Z",
     "iopub.status.busy": "2025-04-13T16:03:19.322433Z",
     "iopub.status.idle": "2025-04-13T16:03:19.384594Z",
     "shell.execute_reply": "2025-04-13T16:03:19.383931Z",
     "shell.execute_reply.started": "2025-04-13T16:03:19.322660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracting Predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting choices: 100%|██████████| 200/200 [00:00<00:00, 3664.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "     Your explanation should be related to David's self-...on himself when he cannot master a section of one of his pieces. Which of the following answers best'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the relationships between the domains.\n",
      "     Yo...e order Archaea, Eukarya, and Bacteria.\n",
      "     You may assume that the domains are in the order Archae'\n",
      "Warning: Could not extract answer from text: '- Exhaustion, confusion, and unresponsiveness are symptoms that can occur in various conditions, inc...ilure is characterized by symptoms such as shortness of breath, chest pain, and difficulty breathing'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the question.\n",
      "\"\n",
      "\n",
      "The boy's symptoms of fever, ...ponsible for the boy's bone infection and the symptoms of fever, swelling, and recurrent infections.'\n",
      "Warning: Could not extract answer from text: '- The mandible is the lower jaw, and its elevation is crucial for maintaining the bite.\n",
      "     - The m...n of the mandible.\n",
      "     - The lateral pterygoid muscle is the muscle that initiates the elevation of'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise, with no unnecessary details.\n",
      "     Your reasoning should ....\n",
      "     Your final answer should be selected from the options given.\n",
      "     Your final answer should be'\n",
      "Warning: Could not extract answer from text: '-\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "</think>\n",
      "The question is about identifying the class of antibodies that are charac...ent on the surface of the plasma cells themselves.\n",
      "\n",
      "Therefore, the correct answer is IgM antibodies.'\n",
      "Warning: Could not extract answer from text: '- Cystic fibrosis is a genetic disorder caused by mutations in the CFTR gene.\n",
      "     - The CFTR gene i...uired for the production of cystatin, which is essential for the proper functioning of the lungs and'\n",
      "Warning: Could not extract answer from text: '- The urea cycle involves the conversion of ammonia to urea, and the regeneration of ornithine is a ...cond step in the citric acid cycle.\n",
      "     - The conversion of fumarate to oxaloacetate is the reverse'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "     Your explanation should be detailed and directly ad...r explanation should be in the same language as the question.\n",
      "     Your explanation should be in the'\n",
      "Warning: Could not extract answer from text: '- In the first medium, the sound has a certain velocity, intensity, frequency, and wavelength.\n",
      "     ...which means the intensity increases.\n",
      "     - The sound waves are more spread out in the denser medium'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the clinical considerations relevant to the pa...fore, her eligibility to receive Medicare is a relevant factor in determining her treatment options.'\n",
      "Warning: Could not extract answer from text: '- The diaphragm is a structure that separates the thoracic and abdominal cavity.\n",
      "     - The diaphrag...m the thoracic cavity.\n",
      "     - The diaphragm is not responsible for separating the pericardial cavity'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise, with no unnecessary details.\n",
      "     Your explanation shoul...  Your response should be in the form of a single, concise sentence.\n",
      "     Your response should be in'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be clear and concise.\n",
      "     You may refer to any medical text or reference sour... use any symbolic quantifier notation.\n",
      "     You may use any symbolic propositional calculus notation'\n",
      "Warning: Could not extract answer from text: 'Your reasoning should be concise and directly address the question.\n",
      "     Your reasoning should be in....\n",
      "     Proper punctuation.\n",
      "     Proper capitalization.\n",
      "     Proper grammar.\n",
      "     Proper punctuation.'\n",
      "Warning: Could not extract answer from text: 'In the KIHD study, sauna use was found to be associated with a 27% reduction in cardiovascular-relat...e of the stressor. Hormesis triggers a vast array of protective mechanisms that not only repair cell'\n",
      "\n",
      "------------------------------\n",
      "Number of invalid responces: 17\n",
      "\n",
      "Example Extracted Prediction:\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Extracting Predictions ---\")\n",
    "predictions = [extract_choice_mcq(text) for text in tqdm(all_outputs_text, desc=\"Extracting choices\")]\n",
    "num_invalid_responces = predictions.count(None)\n",
    "print(f\"\\n------------------------------\\nNumber of invalid responces: {num_invalid_responces}\")\n",
    "\n",
    "if len(predictions) > 0:\n",
    "    print(\"\\nExample Extracted Prediction:\")\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:03:19.385613Z",
     "iopub.status.busy": "2025-04-13T16:03:19.385349Z",
     "iopub.status.idle": "2025-04-13T16:03:19.417132Z",
     "shell.execute_reply": "2025-04-13T16:03:19.416401Z",
     "shell.execute_reply.started": "2025-04-13T16:03:19.385590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Metrics ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Calculating Metrics ---\")\n",
    "correct_count = 0\n",
    "total_count = len(predictions)\n",
    "results_by_subject = {}\n",
    "\n",
    "if total_count != len(ground_truths):\n",
    "     print(f\"Warning: Mismatch between number of predictions ({total_count}) and ground truths ({len(ground_truths)}). This should not happen.\")\n",
    "     total_count = min(total_count, len(ground_truths))\n",
    "\n",
    "for i in range(total_count):\n",
    "    original_data_index = original_indices[i] if 'original_indices' in locals() else i\n",
    "    data_item = ds_mmlu[original_data_index]\n",
    "    subject = data_item.get('subject', 'Unknown')\n",
    "\n",
    "    pred = predictions[i]\n",
    "    truth = ground_truths[i]\n",
    "    is_correct = (pred == truth)\n",
    "\n",
    "    if subject not in results_by_subject:\n",
    "        results_by_subject[subject] = {'correct': 0, 'total': 0}\n",
    "\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "        results_by_subject[subject]['correct'] += 1\n",
    "    results_by_subject[subject]['total'] += 1\n",
    "\n",
    "overall_accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:03:19.418305Z",
     "iopub.status.busy": "2025-04-13T16:03:19.417938Z",
     "iopub.status.idle": "2025-04-13T16:03:19.423698Z",
     "shell.execute_reply": "2025-04-13T16:03:19.422913Z",
     "shell.execute_reply.started": "2025-04-13T16:03:19.418278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Model Evaluated: MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged\n",
      "Dataset Used: cais/mmlu\n",
      "Number of Questions Evaluated: 200\n",
      "Number of Correct Answers: 57\n",
      "Overall Accuracy: 28.50%\n",
      "\n",
      "Accuracy by Subject:\n",
      "- anatomy: 29.03% (9/31)\n",
      "- clinical_knowledge: 31.03% (9/29)\n",
      "- college_biology: 18.52% (5/27)\n",
      "- college_medicine: 20.00% (6/30)\n",
      "- medical_genetics: 50.00% (14/28)\n",
      "- professional_medicine: 25.45% (14/55)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"Model Evaluated: {MODEL_NAME}\")\n",
    "print(f\"Dataset Used: {DATASET_MMLU}\")\n",
    "print(f\"Number of Questions Evaluated: {total_count}\")\n",
    "print(f\"Number of Correct Answers: {correct_count}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nAccuracy by Subject:\")\n",
    "sorted_subjects = sorted(results_by_subject.keys())\n",
    "for subject in sorted_subjects:\n",
    "    counts = results_by_subject[subject]\n",
    "    sub_acc = (counts['correct'] / counts['total']) * 100 if counts['total'] > 0 else 0\n",
    "    print(f\"- {subject}: {sub_acc:.2f}% ({counts['correct']}/{counts['total']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PubMedQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:17.229173Z",
     "iopub.status.busy": "2025-04-13T16:36:17.228813Z",
     "iopub.status.idle": "2025-04-13T16:36:17.234436Z",
     "shell.execute_reply": "2025-04-13T16:36:17.233404Z",
     "shell.execute_reply.started": "2025-04-13T16:36:17.229126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 4242\n",
    "BATCH_SIZE = 4\n",
    "NUM_SAMPLES = 200\n",
    "DATASET_PUBMEDQA = \"qiaojin/PubMedQA\"\n",
    "SUBSET_PUBMEDQA = \"pqa_labeled\"\n",
    "SPLIT_PUBMEDQA = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:17.235953Z",
     "iopub.status.busy": "2025-04-13T16:36:17.235599Z",
     "iopub.status.idle": "2025-04-13T16:36:18.845376Z",
     "shell.execute_reply": "2025-04-13T16:36:18.844824Z",
     "shell.execute_reply.started": "2025-04-13T16:36:17.235928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24204e13fc8f4ee1a507c0067eb6889d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87646e4864474e9010257d57cc7800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2e94577b5b45db8adafb82764cb883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pubmedqa = load_dataset(DATASET_PUBMEDQA, SUBSET_PUBMEDQA, split=SPLIT_PUBMEDQA)\n",
    "ds_pubmedqa = ds_pubmedqa.shuffle(seed=SEED).select(range(NUM_SAMPLES))\n",
    "ds_pubmedqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.846586Z",
     "iopub.status.busy": "2025-04-13T16:36:18.846101Z",
     "iopub.status.idle": "2025-04-13T16:36:18.853961Z",
     "shell.execute_reply": "2025-04-13T16:36:18.853026Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.846547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pubid': 22504515,\n",
       " 'question': 'Endovenous laser ablation in the treatment of small saphenous varicose veins: does site of access influence early outcomes?',\n",
       " 'context': {'contexts': ['The study was performed to evaluate the clinical and technical efficacy of endovenous laser ablation (EVLA) of small saphenous varicosities, particularly in relation to the site of endovenous access.',\n",
       "   'Totally 59 patients with unilateral saphenopopliteal junction incompetence and small saphenous vein reflux underwent EVLA (810 nm, 14 W diode laser) with ambulatory phlebectomies. Small saphenous vein access was gained at the lowest site of truncal reflux. Patients were divided into 2 groups: access gained above mid-calf (AMC, n = 33) and below mid-calf (BMC, n = 26) levels. Outcomes included Venous Clinical Severity Scores (VCSS), Aberdeen Varicose Vein Questionnaire (AVVQ), patient satisfaction, complications, and recurrence rates.',\n",
       "   'Both groups demonstrated significant improvement in VCSS, AVVQ, generic quality of life Short Form 36, and EuroQol scores (P<.05) up to 1 year. No differences were seen between AMC and BMC groups for complications (phlebitis: 2 [6%] and 1 [3.8%], P>.05; paresthesia: 2 [6%] and 5 [19%], P = .223) and recurrence (3 [9%] and 1 [3.8%], P = .623), respectively.'],\n",
       "  'labels': ['OBJECTIVE', 'METHODS', 'RESULTS'],\n",
       "  'meshes': ['Adult',\n",
       "   'Ambulatory Surgical Procedures',\n",
       "   'Chi-Square Distribution',\n",
       "   'Endovascular Procedures',\n",
       "   'England',\n",
       "   'Female',\n",
       "   'Humans',\n",
       "   'Laser Therapy',\n",
       "   'Lasers, Semiconductor',\n",
       "   'Male',\n",
       "   'Middle Aged',\n",
       "   'Paresthesia',\n",
       "   'Patient Satisfaction',\n",
       "   'Peripheral Nerve Injuries',\n",
       "   'Phlebitis',\n",
       "   'Prospective Studies',\n",
       "   'Quality of Life',\n",
       "   'Recurrence',\n",
       "   'Risk Assessment',\n",
       "   'Risk Factors',\n",
       "   'Saphenous Vein',\n",
       "   'Severity of Illness Index',\n",
       "   'Surveys and Questionnaires',\n",
       "   'Time Factors',\n",
       "   'Treatment Outcome',\n",
       "   'Varicose Veins'],\n",
       "  'reasoning_required_pred': ['n', 'o'],\n",
       "  'reasoning_free_pred': ['n', 'o']},\n",
       " 'long_answer': 'The site of access in our study does not appear to influence complications specifically neural injury or recurrence rates.',\n",
       " 'final_decision': 'no'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pubmedqa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.856478Z",
     "iopub.status.busy": "2025-04-13T16:36:18.856215Z",
     "iopub.status.idle": "2025-04-13T16:36:18.868493Z",
     "shell.execute_reply": "2025-04-13T16:36:18.867732Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.856460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_prompt_pubmedqa(example):\n",
    "    \"\"\"Formats a single example into a prompt for the LLM.\"\"\"\n",
    "    question = example['question']\n",
    "    if not isinstance(example.get('context'), dict) or 'contexts' not in example['context']:\n",
    "        print(f\"Warning: Skipping example due to missing or invalid context field.\")\n",
    "        return None\n",
    "\n",
    "    context_passages = example['context']['contexts']\n",
    "    full_context = \"\\n\\n\".join(context_passages)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in analyzing scientific texts and answering questions based on provided context and explaining your reasoning clearly.\n",
    "Your task is to determine the answer to the question ('yes', 'no', or 'maybe') based only on the information given in the context. Follow these steps:\n",
    "1. Analyze the provided context in relation to the question. Summarize the key evidence (or lack thereof) relevant to answering the question. This is your reasoning.\n",
    "2. Based on your reasoning from the context, determine if the answer to the question is 'yes', 'no', or 'maybe'.\n",
    "3. Output your reasoning first. After the reasoning, start a new line and provide the final decision in the specific format: Answer: [yes/no/maybe]\n",
    "\n",
    "Context:\n",
    "{full_context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Reasoning:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.869568Z",
     "iopub.status.busy": "2025-04-13T16:36:18.869324Z",
     "iopub.status.idle": "2025-04-13T16:36:18.881283Z",
     "shell.execute_reply": "2025-04-13T16:36:18.880569Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.869554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_ground_truth_pubmedqa(example):\n",
    "    \"\"\"Extracts the ground truth ('yes', 'no', 'maybe') from the example.\"\"\"\n",
    "    decision = example.get('final_decision')\n",
    "    if decision not in ['yes', 'no', 'maybe']:\n",
    "        print(f\"Warning: Invalid 'final_decision' value found: {decision}. Skipping ground truth.\")\n",
    "        return None\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.882220Z",
     "iopub.status.busy": "2025-04-13T16:36:18.881997Z",
     "iopub.status.idle": "2025-04-13T16:36:18.891889Z",
     "shell.execute_reply": "2025-04-13T16:36:18.891324Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.882196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_yes_no_maybe(generated_text):\n",
    "    \"\"\"Extracts the predicted choice (yes, no, maybe) from the LLM's output.\"\"\"\n",
    "    text = generated_text.strip().lower()\n",
    "\n",
    "    # Explicit \"Answer: yes/no/maybe\" potentially followed by punctuation/eos\n",
    "    match = re.search(r'(?:answer|decision)\\s*[:\\-]?\\s*(yes|no|maybe)\\b', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    # Look for the first occurrence of \"yes\", \"no\", or \"maybe\" as a whole word\n",
    "    match = re.search(r'\\b(yes|no|maybe)\\b', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    # Fallback - If no clear choice found, return None\n",
    "    print(f\"Warning: Could not extract answer from text: '{text[:100]}...{text[-100:]}'\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.892767Z",
     "iopub.status.busy": "2025-04-13T16:36:18.892570Z",
     "iopub.status.idle": "2025-04-13T16:36:18.943259Z",
     "shell.execute_reply": "2025-04-13T16:36:18.942409Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.892753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Prompts and Ground Truths ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting prompts: 100%|██████████| 200/200 [00:00<00:00, 5963.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prompt:\n",
      "\n",
      "You are an expert in analyzing scientific texts and answering questions based on provided context and explaining your reasoning clearly.\n",
      "Your task is to determine the answer to the question ('yes', 'no', or 'maybe') based only on the information given in the context. Follow these steps:\n",
      "1. Analyze the provided context in relation to the question. Summarize the key evidence (or lack thereof) relevant to answering the question. This is your reasoning.\n",
      "2. Based on your reasoning from the context, determine if the answer to the question is 'yes', 'no', or 'maybe'.\n",
      "3. Output your reasoning first. After the reasoning, start a new line and provide the final decision in the specific format: Answer: [yes/no/maybe]\n",
      "\n",
      "Context:\n",
      "The study was performed to evaluate the clinical and technical efficacy of endovenous laser ablation (EVLA) of small saphenous varicosities, particularly in relation to the site of endovenous access.\n",
      "\n",
      "Totally 59 patients with unilateral saphenopopliteal junction incompetence and small saphenous vein reflux underwent EVLA (810 nm, 14 W diode laser) with ambulatory phlebectomies. Small saphenous vein access was gained at the lowest site of truncal reflux. Patients were divided into 2 groups: access gained above mid-calf (AMC, n = 33) and below mid-calf (BMC, n = 26) levels. Outcomes included Venous Clinical Severity Scores (VCSS), Aberdeen Varicose Vein Questionnaire (AVVQ), patient satisfaction, complications, and recurrence rates.\n",
      "\n",
      "Both groups demonstrated significant improvement in VCSS, AVVQ, generic quality of life Short Form 36, and EuroQol scores (P<.05) up to 1 year. No differences were seen between AMC and BMC groups for complications (phlebitis: 2 [6%] and 1 [3.8%], P>.05; paresthesia: 2 [6%] and 5 [19%], P = .223) and recurrence (3 [9%] and 1 [3.8%], P = .623), respectively.\n",
      "\n",
      "Question: Endovenous laser ablation in the treatment of small saphenous varicose veins: does site of access influence early outcomes?\n",
      "\n",
      "Reasoning:\n",
      "    \n",
      "Corresponding Ground Truth: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing Prompts and Ground Truths ---\")\n",
    "prompts = []\n",
    "ground_truths_raw = []\n",
    "original_indices_map = []\n",
    "\n",
    "for i, ex in enumerate(tqdm(ds_pubmedqa, desc=\"Formatting prompts\")):\n",
    "    prompt = format_prompt_pubmedqa(ex)\n",
    "    if prompt:\n",
    "        prompts.append(prompt)\n",
    "        ground_truths_raw.append(get_ground_truth_pubmedqa(ex))\n",
    "        original_indices_map.append(i)\n",
    "\n",
    "valid_indices = [i for i, gt in enumerate(ground_truths_raw) if gt is not None]\n",
    "\n",
    "if len(valid_indices) < len(prompts):\n",
    "     invalid_gt_count = len(prompts) - len(valid_indices)\n",
    "     print(f\"Warning: {invalid_gt_count} examples had invalid ground truths and were excluded.\")\n",
    "     prompts = [prompts[i] for i in valid_indices]\n",
    "     ground_truths = [ground_truths_raw[i] for i in valid_indices]\n",
    "     original_indices = [original_indices_map[i] for i in valid_indices]\n",
    "else:\n",
    "    ground_truths = ground_truths_raw\n",
    "    original_indices = original_indices_map\n",
    "\n",
    "if len(prompts) > 0:\n",
    "    print(\"\\nExample Prompt:\")\n",
    "    print(prompts[0])\n",
    "    print(f\"Corresponding Ground Truth: {ground_truths[0]}\")\n",
    "else:\n",
    "    print(\"No valid prompts to evaluate.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:36:18.944501Z",
     "iopub.status.busy": "2025-04-13T16:36:18.944162Z",
     "iopub.status.idle": "2025-04-13T17:12:06.633963Z",
     "shell.execute_reply": "2025-04-13T17:12:06.633117Z",
     "shell.execute_reply.started": "2025-04-13T16:36:18.944486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Responses: 100%|██████████| 50/50 [35:47<00:00, 42.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Generated Text (raw):\n",
      "...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Inference ---\")\n",
    "all_outputs_text = []\n",
    "num_batches = math.ceil(len(prompts) / BATCH_SIZE)\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Responses\"):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, len(prompts))\n",
    "    batch_prompts = prompts[start_idx:end_idx]\n",
    "    outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=False)\n",
    "    batch_outputs_text = [output.outputs[0].text.strip() for output in outputs]\n",
    "    all_outputs_text.extend(batch_outputs_text)\n",
    "\n",
    "if len(all_outputs_text) > 0:\n",
    "    print(\"\\nExample Generated Text (raw):\")\n",
    "    print(all_outputs_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T17:12:06.635431Z",
     "iopub.status.busy": "2025-04-13T17:12:06.634958Z",
     "iopub.status.idle": "2025-04-13T17:12:06.682348Z",
     "shell.execute_reply": "2025-04-13T17:12:06.681646Z",
     "shell.execute_reply.started": "2025-04-13T17:12:06.635405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracting Predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting choices: 100%|██████████| 200/200 [00:00<00:00, 5071.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: 'the question is about the quality of storage of vaccines in the community. the context provides info...torage conditions for the vaccines; eight had minimum and maximum thermometers but only one of these'\n",
      "Warning: Could not extract answer from text: 'the study included 3-phase bone scintigraphy, which was used to determine the amputation level. the ...a 3-phase bone scintigraphy, the use of a 3-phase bone scintigraphy, the use of a 3-phase bone scint'\n",
      "Warning: Could not extract answer from text: '...\n",
      "final decision:\n",
      "</think>\n",
      "the question is asking whether routine laboratory markers are useful fo...nash from ash, as they were identified as relevant regressors and supported by the study's findings.'\n",
      "Warning: Could not extract answer from text: 'in the study, the proportion of medical records without opioid dependence was 70% (95% ci, 60%-80%).... was 70%, the proportion of records without mmt documentation was 89%, and the proportion of records'\n",
      "Warning: Could not extract answer from text: 'the study found that healthier lifestyles are associated with less utilization of healthcare resourc... higher frequency of regular physical exercise, which is beneficial for reducing the risk of chronic'\n",
      "Warning: Could not extract answer from text: 'the treatment of amblyopia normalises subfoveal choroidal thickness in amblyopic children.\n",
      "     the ... the treatment of amblyopia normalises subfoveal choroidal thickness in amblyopic children.\n",
      "     the'\n",
      "Warning: Could not extract answer from text: 'the laboratory findings indicate that the fibronectin-aggrecan complex is present in the lavage flui... is present in the lavage fluid. this complex is a component of the fac, which is a key component of'\n",
      "Warning: Could not extract answer from text: 'the ph strip was brought into contact with the vaginal fluid on the sampling device and on the glass...e. the ph strip was then placed on the glass slide. the ph strip was then placed on the glass slide.'\n",
      "Warning: Could not extract answer from text: '- in bivariate analysis, children with a regular clinician for preventive care reported slightly hig...nd hispanic children.\n",
      "     - therefore, the study's findings suggest that having a regular clinician'\n",
      "Warning: Could not extract answer from text: '- the studies examined the relationship between appendectomy and infertility or ectopic pregnancy.\n",
      " ... pregnancy were 1.6 (95% ci 1.1 to 2.5).\n",
      "     - the risk estimates for tubal infertility were 4.8 (9'\n",
      "Warning: Could not extract answer from text: '1. adma levels were significantly reduced in ex-elbw subjects compared to c.\n",
      "     2. adma levels wer...ma levels were significantly correlated inversely with the chronological age of the subject.\n",
      "     18'\n",
      "Warning: Could not extract answer from text: 'the analysis shows that laparoscopic surgery is associated with a lower risk of atrial fibrillation....fibrillation. the analysis shows that laparoscopic surgery is associated with a lower risk of atrial'\n",
      "Warning: Could not extract answer from text: 'the anova, kruskal-wallis, and mann-whitney u-test were used to compare the biometric characteristic...ound examination. pregnancies with fetal cromosomopathies and malformations were excluded as well as'\n",
      "Warning: Could not extract answer from text: 'the question is about the satisfaction of uk radiologists with the training and support received in ...icated paediatric radiologist, thus in a significant proportion of departments (25%) initial reports'\n",
      "Warning: Could not extract answer from text: 'a. the analysis of the joint line positions by means of the contralateral knee is a new approach for...t perspective and potentially improve clinical outcomes by utilizing the symmetry of the human body.'\n",
      "Warning: Could not extract answer from text: '- the study included 5339 patients, which is a large number, but the number of patients in each stag...icant number of institutions.\n",
      "     - the study included patients from 16 different centers, which is'\n",
      "Warning: Could not extract answer from text: 'in this study, the dose to the ipsilateral parotid gland was 52.8 gy, and the dose to the contralate...d gland (52.8 gy). therefore, the dose to the contralateral parotid gland was 46.6 gy, which is less'\n",
      "Warning: Could not extract answer from text: 'the study examined the relationship between the brooker grades of injury severity and the occurrence...injury severity score, presence of neurologic injury, letournel fracture type, occurrence of hip dis'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: 'the study examined 33 patients with pre-eclampsia and 32 normotensive pregnant patients as controls.... findings were supported by the fact that the mean age of the patients with pre-eclampsia was 29.6 ±'\n",
      "Warning: Could not extract answer from text: '...\n",
      "final decision:\n",
      "</think>\n",
      "the question is asking whether ganglionated plexi (gp) ablation during ...lation during the maze iv procedure is not beneficial for maintaining a stable sinus rhythm post-op.'\n",
      "Warning: Could not extract answer from text: 'the study found that brca1 carriers had a median survival of 46.0 years, while brca2 carriers had a ...a1 carriers have a slightly better 1 - c-index value than brca2 carriers, indicating that the models'\n",
      "Warning: Could not extract answer from text: 'in the study, iadls were measured using pooled activities from five informant-based questionnaires. ...p = .04). this suggests that iadl disability could help predict dementia in addition to the measured'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: 'in the kell group, 4 out of 42 (10%) of the fetuses had a thrombocytopenia defined as a platelet cou...ropic fetuses had a clinically significant thrombocytopenia. in the rhd group, 2/230 (1%) of the non'\n",
      "Warning: Could not extract answer from text: 'the study examined the relationship between the presentation of twin a at 28 weeks and 32 weeks. it ...e study shows that the positive predictive value of cephalic presentation of twin a as determined by'\n",
      "Warning: Could not extract answer from text: 'the surgical treatment of diabetes has evolved from complex pancreatic and islets transplantation su...cal treatment of diabetes is evolving from complex pancreatic and islets transplantation surgery for'\n",
      "Warning: Could not extract answer from text: 'the clinical difficulty in using this approach lies in determining which type ii schfs can be manage...operatively. the clinical difficulty is due to the fact that it is difficult to determine which type'\n",
      "Warning: Could not extract answer from text: 'the study examined the effect of affect-regulated exercise training on physical health gains. it inv...lead to improved physical health gains. the training group experienced a significant increase in the'\n",
      "Warning: Could not extract answer from text: 'the data collected from the retrospective chart review of elbw infants admitted to a level iii nicu ...d was able to identify 84% of instances where paco2 was between 35 and 55 mmhg. the bias was 5.6 mmh'\n",
      "Warning: Could not extract answer from text: '...\n",
      "answer:\n",
      "</think>\n",
      "the question is about whether to continue offering a second-look laparotomy (sl...omprehensive evaluation of the patient's individual circumstances and the specific clinical context.'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: 'the ace gene is a gene that encodes a protein called ace, which is important for the conversion of i...lso associated with increased levels of homa %, which is a measure of insulin sensitivity. the study'\n",
      "Warning: Could not extract answer from text: '1. the study examined the relationship between resected stomach volume and weight loss after lsg.\n",
      "  ...weight loss after lsg.\n",
      "     168. the study concluded that resected stomach volume was not related to'\n",
      "Warning: Could not extract answer from text: 'in the saline group, the ovarian sections revealed higher scores for follicular degeneration and ede...nce suggests that edaravone provides protection against ischemia/reperfusion-induced ovarian damage.'\n",
      "Warning: Could not extract answer from text: 'in 1996, 54.8% of uninsured persons in managed care had a usual source of care, while 62.2% of unins...re. therefore, in 1996, 54.8% of uninsured persons in managed care had a usual source of care, while'\n",
      "Warning: Could not extract answer from text: 'the study's findings indicate that the optical diagnosis of polyp histology is highly accurate, with...for predicting colonoscopy surveillance intervals. therefore, the study's findings indicate that the'\n",
      "Warning: Could not extract answer from text: '- all patients should undergo a portoenterostomy.\n",
      "     - all patients should undergo a portoenterost...her relevant factors.\n",
      "\n",
      "therefore, the answer is: not all patients should undergo a portoenterostomy.'\n",
      "Warning: Could not extract answer from text: 'the surgical management of the atherosclerotic ascending aorta has been proposed as an alternative t...n alternative to conventional cross-clamping to prevent injury to the vessel and distal embolization'\n",
      "Warning: Could not extract answer from text: 'in the context, it is stated that 23 subjects with cryptogenic chronic hepatitis were evaluated for ...r disease. therefore, tt virus-dna is not involved in the evaluation of hepatitis g virus-rna in the'\n",
      "Warning: Could not extract answer from text: 'all patients had a routine chest x-ray performed 2 hours after the procedure. of the 350 patients, 1...december 2001 and january 2004. routine cxr was performed up to 2 h after the procedure in all cases'\n",
      "Warning: Could not extract answer from text: 'the study included 39 stroke patients, and 1027 monitor and 716 booklet readings were recorded. nine... systolic and 0.3 mmhg diastolic. the average readings on the monitor were 0.6 mmhg systolic and 0.3'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: '1. the question is about the awareness of side effects of ace-i.\n",
      "     2. the study involved 154 phys...ore aware of the side effects of ace-i compared to cardiologists and allergists.\n",
      "     141. the study'\n",
      "Warning: Could not extract answer from text: 'aripiprazole: a new risk factor for pathological gambling\n",
      "     aripiprazole: a new risk factor for p...ctor for pathological gambling\n",
      "     aripiprazole: a new risk factor for pathological gambling\n",
      "     a'\n",
      "Warning: Could not extract answer from text: 'the study involved 50 children with communicating hydrocephalus and 34 with non-communicating hydroc...the type of hydrocephalus. the study concluded that the shape of the third ventricle was the only ct'\n",
      "Warning: Could not extract answer from text: 'cyp2d6*4 allele is found in 22% of breast cancer patients and 1% of healthy volunteers. the odds rat...up is 0.70, and the odds ratio for the homozygous group is 0.22. the odds ratio for the heterozygous'\n",
      "Warning: Could not extract answer from text: 'the preresidency selection criteria examined included united states medical licensing examination (u...r of away rotations, alpha omega alpha (aoa) honor medical society membership, fourth-year subintern'\n",
      "Warning: Could not extract answer from text: 'the study found that 77% of drivers of passenger vehicles were aware of esc, and 63% of those who kn...g changes in their driving behavior since they began driving the vehicle.\n",
      "\n",
      "the study also found that'\n",
      "Warning: Could not extract answer from text: 'the study examined the relationship between gynecological alarm symptoms and contact with specialist...ion is linked to a greater likelihood of seeking specialist care, and higher socioeconomic status is'\n",
      "Warning: Could not extract answer from text: 'before the procedure, the gfr was 100% normal. after the procedure, the gfr was 99% normal. the gfr ...and 3 mo after surgery. the gfr was not significantly different before and 3 mo after surgery. the g'\n",
      "Warning: Could not extract answer from text: 'in the study, 35 study and 64 control patients were identified. both groups were similar in age and .... the chi(2) value is greater than 5, suggesting a significant association. the p value is less than'\n",
      "Warning: Could not extract answer from text: 'the study's focus is on internal breast node-negative tumours, which are not the same as central or ...ve tumours. the study does not provide any information about the effect of chest wall irradiation on'\n",
      "Warning: Could not extract answer from text: 'the most rotated vertebra (or disc) levels were compared with the regional and global apex levels (v...gher variability, extending up to two levels for the global apex (95% confidence levels: -1.19, +1.5'\n",
      "Warning: Could not extract answer from text: '- the study describes the epidemiological characteristics of shigellosis in barcelona, including the...pulation.\n",
      "     - the study does not mention any specific characteristics of the disease that suggest'\n",
      "Warning: Could not extract answer from text: '- the study involved 55 patients with complete follow-up on 23 patients.\n",
      "     - most participants we...an.\n",
      "     - most participants were 46 years old.\n",
      "     - most participants were less than $20,000/year'\n",
      "Warning: Could not extract answer from text: 'in 2015, the catholic bishops called for a boycott of the polio vaccination campaign. this call was ...s/guardians.\n",
      "the call for the boycott by the catholic bishops may have had a more significant impact'\n",
      "Warning: Could not extract answer from text: 'the study examined themri of the distal femoral epiphysis, particularly the secondary physis, in chi... ocd. the study concluded that the lesions were more likely to be in the middle and posterior thirds'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "Warning: Could not extract answer from text: 'in this study, the researchers compared two methods for predicting admission: gaps and vas. they use...alibration and discrimination. therefore, gaps was a better overall method for predicting admission.'\n",
      "Warning: Could not extract answer from text: 'in the subset of high-grade and large tumors, tumor depth was found to be associated with poor survi...s, which had a larger mean size than the superficial tumors. the larger mean size of the deep-seated'\n",
      "Warning: Could not extract answer from text: 'the intracerebroventricular injection of metformin or aicar on the plasma concentrations of melatoni... the ewe: potential involvement of ampk?\n",
      "the intracerebroventricular injection of metformin or aicar'\n",
      "Warning: Could not extract answer from text: '- the study involved 19 patients who received brachytherapy after radiochemotherapy.\n",
      "     - the pibs...n a region with a high incidence of cervical cancer.\n",
      "     - the study was conducted in a region with'\n",
      "Warning: Could not extract answer from text: 'the study involved elderly patients who were randomly recruited from a health clinic in buenos aires...higher for patients with a tertiary education compared to those with a primary school education.\n",
      "the'\n",
      "Warning: Could not extract answer from text: 'in the ics-naive group, the vas score was [high/low/neutral], and in the ics-treated group, the vas ... a vas score of [high/low/neutral], and the ics-treated group had a vas score of [high/low/neutral].'\n",
      "Warning: Could not extract answer from text: '- the mean ct-attenuation values and the standard deviation were recorded separately and compared wi...toshiba model were significantly different from those obtained with the siemens and the philips, but'\n",
      "Warning: Could not extract answer from text: '...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     .....\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...\n",
      "     ...'\n",
      "\n",
      "------------------------------\n",
      "Number of invalid responces: 68\n",
      "\n",
      "Example Extracted Prediction:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Extracting Predictions ---\")\n",
    "predictions = [extract_yes_no_maybe(text) for text in tqdm(all_outputs_text, desc=\"Extracting choices\")]\n",
    "num_invalid_responсes = predictions.count(None)\n",
    "print(f\"\\n------------------------------\\nNumber of invalid responces: {num_invalid_responсes}\")\n",
    "\n",
    "if len(predictions) > 0:\n",
    "    print(\"\\nExample Extracted Prediction:\")\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T17:12:06.683480Z",
     "iopub.status.busy": "2025-04-13T17:12:06.683160Z",
     "iopub.status.idle": "2025-04-13T17:12:06.722523Z",
     "shell.execute_reply": "2025-04-13T17:12:06.721788Z",
     "shell.execute_reply.started": "2025-04-13T17:12:06.683456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Metrics ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Calculating Metrics ---\")\n",
    "correct_count = 0\n",
    "total_count = len(predictions)\n",
    "results_by_subject = {}\n",
    "\n",
    "if total_count != len(ground_truths):\n",
    "     print(f\"Warning: Mismatch between number of predictions ({total_count}) and ground truths ({len(ground_truths)}). This should not happen.\")\n",
    "     total_count = min(total_count, len(ground_truths))\n",
    "\n",
    "for i in range(total_count):\n",
    "    original_data_index = original_indices[i] if 'original_indices' in locals() else i\n",
    "    data_item = ds_pubmedqa[original_data_index]\n",
    "    subject = data_item.get('subject_name', 'Unknown')\n",
    "\n",
    "    pred = predictions[i]\n",
    "    truth = ground_truths[i]\n",
    "    is_correct = (pred == truth)\n",
    "\n",
    "    if subject not in results_by_subject:\n",
    "        results_by_subject[subject] = {'correct': 0, 'total': 0}\n",
    "\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "        results_by_subject[subject]['correct'] += 1\n",
    "    results_by_subject[subject]['total'] += 1\n",
    "\n",
    "overall_accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T17:12:06.723520Z",
     "iopub.status.busy": "2025-04-13T17:12:06.723240Z",
     "iopub.status.idle": "2025-04-13T17:12:06.727836Z",
     "shell.execute_reply": "2025-04-13T17:12:06.727297Z",
     "shell.execute_reply.started": "2025-04-13T17:12:06.723494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Model Evaluated: MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-medical-sft-merged\n",
      "Dataset Used: qiaojin/PubMedQA\n",
      "Number of Questions Evaluated: 200\n",
      "Number of Correct Answers: 72\n",
      "Overall Accuracy: 36.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"Model Evaluated: {MODEL_NAME}\")\n",
    "print(f\"Dataset Used: {DATASET_PUBMEDQA}\")\n",
    "print(f\"Number of Questions Evaluated: {total_count}\")\n",
    "print(f\"Number of Correct Answers: {correct_count}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
