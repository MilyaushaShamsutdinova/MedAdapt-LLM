{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:17.426434Z",
     "iopub.status.busy": "2025-03-08T01:11:17.426027Z",
     "iopub.status.idle": "2025-03-08T01:11:25.469643Z",
     "shell.execute_reply": "2025-03-08T01:11:25.468693Z",
     "shell.execute_reply.started": "2025-03-08T01:11:17.426396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install transformers datasets trl torch huggingface-hub wandb scikit-learn bitsandbytes accelerate\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:25.471030Z",
     "iopub.status.busy": "2025-03-08T01:11:25.470775Z",
     "iopub.status.idle": "2025-03-08T01:11:29.097460Z",
     "shell.execute_reply": "2025-03-08T01:11:29.096522Z",
     "shell.execute_reply.started": "2025-03-08T01:11:25.470992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "SEED = 4242\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:29.099405Z",
     "iopub.status.busy": "2025-03-08T01:11:29.099148Z",
     "iopub.status.idle": "2025-03-08T01:11:29.403731Z",
     "shell.execute_reply": "2025-03-08T01:11:29.403042Z",
     "shell.execute_reply.started": "2025-03-08T01:11:29.099383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:29.405473Z",
     "iopub.status.busy": "2025-03-08T01:11:29.405150Z",
     "iopub.status.idle": "2025-03-08T01:11:44.129337Z",
     "shell.execute_reply": "2025-03-08T01:11:44.128553Z",
     "shell.execute_reply.started": "2025-03-08T01:11:29.405442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiliusha2801\u001b[0m (\u001b[33mmiliusha2801-innopolis-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250308_011137-7q51lr76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0/runs/7q51lr76' target=\"_blank\">silver-river-3</a></strong> to <a href='https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0' target=\"_blank\">https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0/runs/7q51lr76' target=\"_blank\">https://wandb.ai/miliusha2801-innopolis-university/Deepseek-R1-Qwen-1.5b%20SFT%20on%20medical%20dataset%20full%201%20epoch%20v.0/runs/7q51lr76</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_api = user_secrets.get_secret(\"WANDB_API\")\n",
    "wandb.login(key=wandb_api)\n",
    "\n",
    "run = wandb.init(\n",
    "    project='Deepseek-R1-Qwen-1.5b SFT on medical dataset full 1 epoch v.0',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:44.130519Z",
     "iopub.status.busy": "2025-03-08T01:11:44.130262Z",
     "iopub.status.idle": "2025-03-08T01:11:44.137071Z",
     "shell.execute_reply": "2025-03-08T01:11:44.136224Z",
     "shell.execute_reply.started": "2025-03-08T01:11:44.130495Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:11:44.138376Z",
     "iopub.status.busy": "2025-03-08T01:11:44.138059Z",
     "iopub.status.idle": "2025-03-08T01:12:27.321925Z",
     "shell.execute_reply": "2025-03-08T01:12:27.320738Z",
     "shell.execute_reply.started": "2025-03-08T01:11:44.138343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0386fb7f2e7343919b5ba4d4a6608773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58134c0578b84e439845d883fb9f4948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d0ce606f744545b5151fb8c79834f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e784e98040341e48e53164e69996ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8396ecb0f2e3414eb41b28f683d52047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import setup_chat_format\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "finetune_name = \"DeepSeek-R1-Distill-Qwen-1.5B-Medical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:27.324066Z",
     "iopub.status.busy": "2025-03-08T01:12:27.323166Z",
     "iopub.status.idle": "2025-03-08T01:12:27.330893Z",
     "shell.execute_reply": "2025-03-08T01:12:27.329735Z",
     "shell.execute_reply.started": "2025-03-08T01:12:27.324026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:27.334719Z",
     "iopub.status.busy": "2025-03-08T01:12:27.334422Z",
     "iopub.status.idle": "2025-03-08T01:12:31.402222Z",
     "shell.execute_reply": "2025-03-08T01:12:31.401099Z",
     "shell.execute_reply.started": "2025-03-08T01:12:27.334695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Please answer the following medical question.\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:31.404207Z",
     "iopub.status.busy": "2025-03-08T01:12:31.403931Z",
     "iopub.status.idle": "2025-03-08T01:12:32.223696Z",
     "shell.execute_reply": "2025-03-08T01:12:32.222733Z",
     "shell.execute_reply.started": "2025-03-08T01:12:31.404183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:32.224994Z",
     "iopub.status.busy": "2025-03-08T01:12:32.224663Z",
     "iopub.status.idle": "2025-03-08T01:12:46.422446Z",
     "shell.execute_reply": "2025-03-08T01:12:46.421557Z",
     "shell.execute_reply.started": "2025-03-08T01:12:32.224958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output before training:\n",
      "\n",
      "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
      "Please answer the following medical question.\n",
      "<｜User｜>A 3-year-old child presents with tall stature, developmental delay, joint hypermobility, hyperelastic skin, fair complexion, prominent sternum, and downward lens subluxation in the right eye. Considering these features, what complication is this child most likely to develop? \n",
      "Please provide a detailed explanation of your reasoning.\n",
      "</think>\n",
      "\n",
      "The child presented with several clinical signs that could indicate a developmental delay and may suggest an underlying neurological condition. Here's a detailed analysis of the possible complication:\n",
      "\n",
      "1. **Joint Hypermobility and Downward Lens Subluxation**: The right eye shows downward lens subluxation, a hallmark of a congenital malformation. This suggests a neurological issue, possibly a congenital malformation of the eye.\n",
      "\n",
      "2. **Tall Stature and Developmental Delay**: These are common signs of a developing brain deficit. The combination of height and delay often points to a developmental delay, such as a st tipped brain or a brain in need of intervention.\n",
      "\n",
      "3. **Developmental Delay and Joint Hypermobility**: While hypermobility in the right eye might be more commonly associated with a brain in need of intervention, it could also suggest a developmental delay. However, the joint mobility is a more specific feature often linked to a brain in need of intervention rather than a developmental delay.\n",
      "\n",
      "4. **Consideration for Other Conditions**: While the primary features suggest a developmental delay, the joint hypermobility could also indicate a brain in need of intervention. However, the most likely cause based on the given features is a developmental delay.\n",
      "\n",
      "**Conclusion**: The most likely complication is a brain in need of intervention due to a developmental delay, possibly a brain in need of intervention.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A 3-year-old child presents with tall stature, developmental delay, joint hypermobility, hyperelastic skin, fair complexion, prominent sternum, and downward lens subluxation in the right eye. Considering these features, what complication is this child most likely to develop?\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    # use_cache=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "print(\"Output before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:46.423892Z",
     "iopub.status.busy": "2025-03-08T01:12:46.423565Z",
     "iopub.status.idle": "2025-03-08T01:12:49.983510Z",
     "shell.execute_reply": "2025-03-08T01:12:49.982583Z",
     "shell.execute_reply.started": "2025-03-08T01:12:46.423861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e467c6611a4ee39460cadb6a1d453f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27a0ea751f241029c03473fc634bf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef874c160ea54551a74974db9a062749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# split=\"train[0:500]\"\n",
    "ds = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split=\"train[:20000]\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:49.984765Z",
     "iopub.status.busy": "2025-03-08T01:12:49.984500Z",
     "iopub.status.idle": "2025-03-08T01:12:49.990801Z",
     "shell.execute_reply": "2025-03-08T01:12:49.990103Z",
     "shell.execute_reply.started": "2025-03-08T01:12:49.984742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Question', 'Complex_CoT', 'Response'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:49.991905Z",
     "iopub.status.busy": "2025-03-08T01:12:49.991637Z",
     "iopub.status.idle": "2025-03-08T01:12:50.010401Z",
     "shell.execute_reply": "2025-03-08T01:12:50.009385Z",
     "shell.execute_reply.started": "2025-03-08T01:12:49.991885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?',\n",
       " 'Complex_CoT': \"Okay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\",\n",
       " 'Response': 'Cystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.011796Z",
     "iopub.status.busy": "2025-03-08T01:12:50.011419Z",
     "iopub.status.idle": "2025-03-08T01:12:50.027411Z",
     "shell.execute_reply": "2025-03-08T01:12:50.026551Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.011760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"\n",
    "### Instruction:\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Please answer the following medical question. \n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.028613Z",
     "iopub.status.busy": "2025-03-08T01:12:50.028315Z",
     "iopub.status.idle": "2025-03-08T01:12:50.044081Z",
     "shell.execute_reply": "2025-03-08T01:12:50.043304Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.028589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    questions = examples[\"Question\"]\n",
    "    thoughts = examples[\"Complex_CoT\"]\n",
    "    responses = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for question, thought, response in zip(questions, thoughts, responses):\n",
    "        text = train_prompt_style.format(question, thought, response) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.045099Z",
     "iopub.status.busy": "2025-03-08T01:12:50.044852Z",
     "iopub.status.idle": "2025-03-08T01:12:50.534282Z",
     "shell.execute_reply": "2025-03-08T01:12:50.532931Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.045079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023365c0046845569558bff75bc17d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_formatted = ds.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    "    remove_columns=[\"Question\", \"Complex_CoT\", \"Response\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.535492Z",
     "iopub.status.busy": "2025-03-08T01:12:50.535245Z",
     "iopub.status.idle": "2025-03-08T01:12:50.542181Z",
     "shell.execute_reply": "2025-03-08T01:12:50.541189Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.535469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.\\n<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_formatted[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.543557Z",
     "iopub.status.busy": "2025-03-08T01:12:50.543240Z",
     "iopub.status.idle": "2025-03-08T01:12:50.737258Z",
     "shell.execute_reply": "2025-03-08T01:12:50.736278Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.543529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "\n",
    "ds_splitted = ds_formatted.train_test_split(test_size=0.05, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.738366Z",
     "iopub.status.busy": "2025-03-08T01:12:50.738057Z",
     "iopub.status.idle": "2025-03-08T01:12:50.744703Z",
     "shell.execute_reply": "2025-03-08T01:12:50.744039Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.738339Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 19000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.745809Z",
     "iopub.status.busy": "2025-03-08T01:12:50.745532Z",
     "iopub.status.idle": "2025-03-08T01:12:50.760945Z",
     "shell.execute_reply": "2025-03-08T01:12:50.759937Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.745787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:50.762371Z",
     "iopub.status.busy": "2025-03-08T01:12:50.762103Z",
     "iopub.status.idle": "2025-03-08T01:12:51.202809Z",
     "shell.execute_reply": "2025-03-08T01:12:51.201800Z",
     "shell.execute_reply.started": "2025-03-08T01:12:50.762347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:51.204140Z",
     "iopub.status.busy": "2025-03-08T01:12:51.203802Z",
     "iopub.status.idle": "2025-03-08T01:12:51.277406Z",
     "shell.execute_reply": "2025-03-08T01:12:51.276655Z",
     "shell.execute_reply.started": "2025-03-08T01:12:51.204114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=finetune_name,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_steps=200,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    # optim=\"paged_adamw_32bit\",\n",
    "    optim=\"adamw_torch_fused\", \n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=300,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    seed=SEED,\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    tf32=False,\n",
    "    hub_model_id=finetune_name,\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:12:51.280411Z",
     "iopub.status.busy": "2025-03-08T01:12:51.280150Z",
     "iopub.status.idle": "2025-03-08T01:14:01.466450Z",
     "shell.execute_reply": "2025-03-08T01:14:01.465772Z",
     "shell.execute_reply.started": "2025-03-08T01:12:51.280388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edba0de0180463ebf3d1b802d99f7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/19000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec09fa774e694ae3ac5c17d57a322042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8246b4eefb47abb74dfc939ecde8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d223f19601be4d2f9b901320727e0bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec4e8fd6d6e4ceb9c23a30c850284ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15da88771cf5475bab4cf079e896dc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a469bacbbc2b40f9bce2251a12366484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98f9986593b435d90e6b69c3dc820bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=ds_splitted[\"train\"],\n",
    "    eval_dataset=ds_splitted[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:14:01.467854Z",
     "iopub.status.busy": "2025-03-08T01:14:01.467545Z",
     "iopub.status.idle": "2025-03-08T01:14:01.914367Z",
     "shell.execute_reply": "2025-03-08T01:14:01.913574Z",
     "shell.execute_reply.started": "2025-03-08T01:14:01.467823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T01:14:01.915717Z",
     "iopub.status.busy": "2025-03-08T01:14:01.915362Z",
     "iopub.status.idle": "2025-03-08T12:19:17.256613Z",
     "shell.execute_reply": "2025-03-08T12:19:17.255744Z",
     "shell.execute_reply.started": "2025-03-08T01:14:01.915686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 11:05:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.631000</td>\n",
       "      <td>1.872467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.370800</td>\n",
       "      <td>1.779906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.196900</td>\n",
       "      <td>1.744969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.971600</td>\n",
       "      <td>1.722984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.982600</td>\n",
       "      <td>1.708936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.870700</td>\n",
       "      <td>1.697711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>6.801700</td>\n",
       "      <td>1.688394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>6.803600</td>\n",
       "      <td>1.681025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>6.716700</td>\n",
       "      <td>1.674167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.805200</td>\n",
       "      <td>1.668206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>6.736700</td>\n",
       "      <td>1.662312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>6.778900</td>\n",
       "      <td>1.656689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>6.691700</td>\n",
       "      <td>1.652920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>6.768700</td>\n",
       "      <td>1.648939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.585000</td>\n",
       "      <td>1.645701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>6.584300</td>\n",
       "      <td>1.642681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>1.640624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>6.751900</td>\n",
       "      <td>1.638674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>6.674800</td>\n",
       "      <td>1.637393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.598600</td>\n",
       "      <td>1.636186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>6.670500</td>\n",
       "      <td>1.635486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>6.575500</td>\n",
       "      <td>1.635203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>6.689000</td>\n",
       "      <td>1.635054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2375, training_loss=6.8573771458675985, metrics={'train_runtime': 39914.7107, 'train_samples_per_second': 0.476, 'train_steps_per_second': 0.06, 'total_flos': 1.333256288507351e+17, 'train_loss': 6.8573771458675985})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save fine-tuned adapter and merged model on HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:19:17.257610Z",
     "iopub.status.busy": "2025-03-08T12:19:17.257407Z",
     "iopub.status.idle": "2025-03-08T12:19:23.319137Z",
     "shell.execute_reply": "2025-03-08T12:19:23.318344Z",
     "shell.execute_reply.started": "2025-03-08T12:19:17.257591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c975857b5a4c43438379344677f422b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/73.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3916523708774d328af325c5c2de175f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac363efc4c741a495d4bd125cf5c4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611b76ed8c11494e9d0966407096f638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical/commit/0a291a7717383b2998fc1152905566f2f170890f', commit_message='End of training', commit_description='', oid='0a291a7717383b2998fc1152905566f2f170890f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical', endpoint='https://huggingface.co', repo_type='model', repo_id='MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:22:14.077652Z",
     "iopub.status.busy": "2025-03-08T12:22:14.077272Z",
     "iopub.status.idle": "2025-03-08T12:23:31.605649Z",
     "shell.execute_reply": "2025-03-08T12:23:31.604822Z",
     "shell.execute_reply.started": "2025-03-08T12:22:14.077616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e28d486233e48df9413ddd83229ce73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f44fabf0a645e8a631da5d730fe3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be8198e111949939aa7be09bee2ed9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical/commit/4c7fcd8369053a012c2b53e977f30eecfa2b9e26', commit_message='Upload tokenizer', commit_description='', oid='4c7fcd8369053a012c2b53e977f30eecfa2b9e26', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical', endpoint='https://huggingface.co', repo_type='model', repo_id='MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model = trainer.model.merge_and_unload()\n",
    "\n",
    "merged_model.push_to_hub(trainer.args.hub_model_id, use_temp_dir=False)\n",
    "trainer.tokenizer.push_to_hub(trainer.args.hub_model_id, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:25:02.681856Z",
     "iopub.status.busy": "2025-03-08T12:25:02.681553Z",
     "iopub.status.idle": "2025-03-08T12:25:03.074525Z",
     "shell.execute_reply": "2025-03-08T12:25:03.073745Z",
     "shell.execute_reply.started": "2025-03-08T12:25:02.681832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:41.807804Z",
     "iopub.status.busy": "2025-03-08T12:27:41.807462Z",
     "iopub.status.idle": "2025-03-08T12:28:21.627814Z",
     "shell.execute_reply": "2025-03-08T12:28:21.626385Z",
     "shell.execute_reply.started": "2025-03-08T12:27:41.807777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question = \"What type of cement bonds to tooth structure, provides an anticariogenic effect, has a degree of translucency, and is non-irritating to the pulp?\"\n",
    "generator = pipeline(\"text-generation\", model=\"MilyaShams/DeepSeek-R1-Distill-Qwen-1.5B-Medical\", device=\"cuda\")\n",
    "output = generator([{\"role\": \"user\", \"content\": question}], max_new_tokens=2000, return_full_text=False)[0]\n",
    "print(output[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
