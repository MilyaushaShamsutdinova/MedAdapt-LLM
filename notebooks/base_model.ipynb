{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff20b0ba",
   "metadata": {},
   "source": [
    "# Base model\n",
    "\n",
    "This is notebook for checking inference and knowledge of base model.\n",
    "\n",
    "*Base model*: [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) - the smallest reasoning DeepSeek-R1 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e0b8c",
   "metadata": {},
   "source": [
    "### Check base LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e07f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253fd0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\python_projects\\MedAlign-LLM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-10 15:09:55 [__init__.py:256] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\python_projects\\MedAlign-LLM\\venv\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.51.0. vLLM: 0.8.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=4096,\n",
    "    load_in_4bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172f7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama-3.1\",\n",
    "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"},\n",
    ")\n",
    "model = FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63175f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I need to figure out which vitamin is only provided from animals. I remember that vitamins are usually found in different sources: some are plant-based, others are animal-based.\n",
      "\n",
      "Vitamin C is a carotenoid found in tomatoes, carrots, and spinach. So that's a plant-based source.\n",
      "\n",
      "Vitamin B12 is also known as riboflavin, and it's found in leafy greens like spinach, kale, and also in some fish like salmon. So again, plant-based.\n",
      "\n",
      "Vitamin B7 is something I'm a bit fuzzy on. Wait, I think B7 is something related to bone health. Oh right, it's called thiamine, and it's found in animal feed, specifically in red meat, poultry, and beans. So that's an animal source.\n",
      "\n",
      "Vitamin D is important for bone health. It's found in fish, shellfish, and some fruits. So that's also an animal source.\n",
      "\n",
      "So putting it together, the only vitamin provided from an animal source would be B7, which is thiamine. So the answer should be option B.\n",
      "</think>\n",
      "\n",
      "The correct answer is B. Vitamin B7 (thiamine) is supplied from animal sources.\n",
      "\n",
      "Answer: B\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert in solving multiple-choice questions accurately and explaining your reasoning clearly.\n",
    "Given a question and a list of answer choices (A, B, C, D), your task is to:\n",
    "1. Reason shortly about the question and answer choices to find evidances to support your answer.\n",
    "2. Identify the correct answer.\n",
    "3. Output the final answer in the format: Answer: [Option Letter]\n",
    "\n",
    "Here is a question: Which vitamin is supplied from only animal source?\n",
    "A. Vitamin C\n",
    "B. Vitamin B7\n",
    "C. Vitamin B12\n",
    "D. Vitamin D\n",
    "\n",
    "Reasoning:\n",
    "\"\"\"\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3f962",
   "metadata": {},
   "source": [
    "Correct answer is Vitamin B12.\n",
    "\n",
    "Base model gave wrong answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
